{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Week 1",
   "id": "99ff6ffb2099cf1f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#~source: https: //en.wikipedia.org/wiki/Gradient_descent\n",
    "# code source: https://en.wikipedia.org/w/index.php?title=Gradient_descent&oldid=966271567\n",
    "\n",
    "# 初始值\n",
    "next_x = 6# We start the search at x = 6\n",
    "# 步长系数（学习率）\n",
    "gamma = 0.01# Step size multiplier\n",
    "# 提前停止（系数变化小于此值时停止）\n",
    "precision = 0.00001# Desired precision of result\n",
    "# 最大迭代次数\n",
    "max_iters = 10000# Maximum number of iterations\n",
    "\n",
    "# Derivative\n",
    "#function\n",
    "#求导\n",
    "def df(x):\n",
    "  return 4 * x ** 3 - 9 * x ** 2\n",
    "\n",
    "# 迭代\n",
    "for i in range(max_iters):\n",
    "    current_x = next_x\n",
    "    \n",
    "    #梯度下降\n",
    "    next_x = current_x - gamma * df(current_x)\n",
    "    print(i, next_x, df(current_x))\n",
    "\n",
    "    # 提前停止的判定，计算系数变化了多少，小于阈值后提前停止\n",
    "    step = next_x - current_x\n",
    "    if abs(step) <= precision:\n",
    "        break\n",
    "\n",
    "print(\"Minimum at \", next_x)\n",
    "\n",
    "# The output for the above will be something like \n",
    "# \"Minimum at 2.2499646074278457\""
   ],
   "id": "9c6f65ec7b78157",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Source: https://github.com/mattnedrich/GradientDescentExample\n",
    "# y = mx + b\n",
    "# m is slope, b is y-intercept\n",
    "# 计算均方误差 MSE\n",
    "def compute_error_for_line_given_points(b, m, points):\n",
    "    totalError = 0\n",
    "    for i in range(0, len(points)):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        # 实际的y减去 mx+b 的 y\n",
    "        totalError += (y - (m * x + b)) ** 2\n",
    "    return totalError / float(len(points))"
   ],
   "id": "3670db91466a94b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Source: https://github.com/mattnedrich/GradientDescentExample\n",
    "\n",
    "# 梯度下降用于线性回归\n",
    "def step_gradient(b_current, m_current, points, learningRate):\n",
    "    b_gradient = 0\n",
    "    m_gradient = 0\n",
    "    N = float(len(points))\n",
    "    for i in range(0, len(points)):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        \n",
    "        # 负梯度计算 （Loss Function 对 y_pre的导数，乘以 y_pred 对 m和b的导数\n",
    "        # 除以N是因为有N个样本，相当于取平均值\n",
    "        b_gradient += -(2/N) * (y - ((m_current * x) + b_current))\n",
    "        m_gradient += -(2/N) * x * (y - ((m_current * x) + b_current))\n",
    "    new_b = b_current - (learningRate * b_gradient)\n",
    "    new_m = m_current - (learningRate * m_gradient)\n",
    "    return [new_b, new_m]"
   ],
   "id": "486caad7e44f7d97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 执行梯度下降的函数\n",
    "def gradient_descent_runner(points, starting_b, starting_m, learning_rate, num_iterations):\n",
    "    b = starting_b\n",
    "    m = starting_m\n",
    "    for i in range(num_iterations):\n",
    "        b, m = step_gradient(b, m, array(points), learning_rate)\n",
    "    return [b, m]"
   ],
   "id": "cbf9e2175aa38855",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 用上面的代码合到一起，跑起来\n",
    "def run():\n",
    "    points = genfromtxt(\"data_linearreg.csv\", delimiter=\",\")\n",
    "    learning_rate = 0.0001\n",
    "    initial_b = 0 # initial y-intercept guess\n",
    "    initial_m = 0 # initial slope guess\n",
    "    num_iterations = 1000\n",
    "    print (\"Starting gradient descent at b = {0}, m = {1}, error = {2}\".format(initial_b, initial_m, compute_error_for_line_given_points(initial_b, initial_m, points)))\n",
    "    print (\"Running...\")\n",
    "    [b, m] = gradient_descent_runner(points, initial_b, initial_m, learning_rate, num_iterations)\n",
    "    print (\"After {0} iterations b = {1}, m = {2}, error = {3}\".format(num_iterations, b, m, compute_error_for_line_given_points(b, m, points)) )"
   ],
   "id": "98de73a2959b92e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#source: https://stackoverflow.com/questions/3949226/calculating-pearson-correlation-and-significance-in-python\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from random import random\n",
    "\n",
    "# 计算 R Score\n",
    "def pcc(X, Y):\n",
    "   ''' Compute Pearson Correlation Coefficient. '''\n",
    "   # Normalise X and Y\n",
    "   X -= X.mean(0)\n",
    "   Y -= Y.mean(0)\n",
    "   # Standardise X and Y\n",
    "   X /= X.std(0)\n",
    "   Y /= Y.std(0)\n",
    "   # Compute mean product\n",
    "   return np.mean(X*Y)\n",
    " \n",
    "def average(x):\n",
    "    assert len(x) > 0\n",
    "    return float(sum(x)) / len(x)\n",
    "\n",
    "def pearson_def(x, y):\n",
    "    assert len(x) == len(y)\n",
    "    n = len(x)\n",
    "    assert n > 0\n",
    "    avg_x = average(x)\n",
    "    avg_y = average(y)\n",
    "    diffprod = 0\n",
    "    xdiff2 = 0\n",
    "    ydiff2 = 0\n",
    "    for idx in range(n):\n",
    "        xdiff = x[idx] - avg_x\n",
    "        ydiff = y[idx] - avg_y\n",
    "        diffprod += xdiff * ydiff\n",
    "        xdiff2 += xdiff * xdiff\n",
    "        ydiff2 += ydiff * ydiff\n",
    "\n",
    "    # 协方差 除以 两个标准差的乘积\n",
    "    return diffprod / math.sqrt(xdiff2 * ydiff2)\n",
    "\n",
    "#main\n",
    "\n",
    "# Using it on a random example\n",
    "\n",
    "X = np.array([random() for x in range(100)])\n",
    "Y = np.array([random() for x in range(100)])\n",
    "\n",
    "\n",
    "# 两种等效的写法\n",
    "pcof = pcc(X, Y)\n",
    "print(pcof, ' is pcof')\n",
    " \n",
    "pcoftwo = pearson_def(X, Y)\n",
    "print(pcoftwo, ' is pcof second version')"
   ],
   "id": "2869b33e623bbfda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Week 2",
   "id": "c4eb0bd5842569c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Source: https://machinelearningmastery.com/implement-logistic-regression-stochastic-gradient-descent-scratch-python/\n",
    "\n",
    "from math import exp\n",
    "\n",
    "# Make a prediction with coefficients\n",
    "# 预测输出的概率 \n",
    "# 先计算 y_hat， 再使用 sigmoid函数转化为概率\n",
    "def predict(row, coefficients):\n",
    "\tyhat = coefficients[0]\n",
    "\tfor i in range(len(row)-1):\n",
    "\t\tyhat += coefficients[i + 1] * row[i]\n",
    "\treturn 1.0 / (1.0 + exp(-yhat))\n",
    "\n",
    "# Estimate logistic regression coefficients using stochastic gradient descent\n",
    "# 梯度下降 更新参数 (权重 w 和 b) \n",
    "# 虽然标注了SGD，但这不是一个随机梯度下降，而是使用 SSE作为损失函数的GD： （全量的）批量梯度下降（如果使用MSE，求导时也要取均值，乘以1/N）\n",
    "def coefficients_sgd(train, l_rate, n_epoch):\n",
    "    # 初始化系数\n",
    "\tcoef = [0.0 for i in range(len(train[0]))]\n",
    "    # 迭代过程\n",
    "\tfor epoch in range(n_epoch):\n",
    "\t\tsum_error = 0\n",
    "        # 循环 遍历每一个sample\n",
    "\t\tfor row in train:\n",
    "            # 计算 预测的prop\n",
    "\t\t\tyhat = predict(row, coef)\n",
    "            # 计算 伪残差\n",
    "\t\t\terror = row[-1] - yhat\n",
    "            # 计算 伪残差平方和，类似MSE\n",
    "\t\t\tsum_error += error**2\n",
    "            # 在原有的 系数基础上，加上 负梯度乘以学习率乘以 sigmoid 的导数\n",
    "            # 这里是在更新 b(bias) wx+b的b\n",
    "\t\t\tcoef[0] = coef[0] + l_rate * error * yhat * (1.0 - yhat)\n",
    "\t\t\t#print(row, yhat, error, sum_error)\n",
    "            # 这里是更新 w\n",
    "\t\t\tfor i in range(len(row)-1):\n",
    "\t\t\t\tcoef[i + 1] = coef[i + 1] + l_rate * error * yhat * (1.0 - yhat) * row[i]\n",
    "\t\tprint('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
    "\treturn coef\n",
    "\n",
    "# Calculate coefficients\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    "\t[1.465489372,2.362125076,0],\n",
    "\t[3.396561688,4.400293529,0],\n",
    "\t[1.38807019,1.850220317,0],\n",
    "\t[3.06407232,3.005305973,0],\n",
    "\t[7.627531214,2.759262235,1],\n",
    "\t[5.332441248,2.088626775,1],\n",
    "\t[6.922596716,1.77106367,1],\n",
    "\t[8.675418651,-0.242068655,1],\n",
    "\t[7.673756466,3.508563011,1]]\n",
    "l_rate = 0.3\n",
    "n_epoch = 10\n",
    "coef = coefficients_sgd(dataset, l_rate, n_epoch)\n",
    "print(coef)"
   ],
   "id": "3f5436804f41688f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    " \n",
    " # by R. Chandra\n",
    " #Source: https://github.com/rohitash-chandra/logistic_regression\n",
    "\n",
    "from math import exp\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "SIGMOID = 1\n",
    "STEP = 2\n",
    "LINEAR = 3\n",
    "\n",
    " \n",
    "random.seed()\n",
    "\n",
    "class logistic_regression:\n",
    "\n",
    "    # num_epocs 迭代次数\n",
    "    # train_data 训练集\n",
    "    # test_data 测试集\n",
    "    # num_features 特征数量\n",
    "    # learn_rate 学习率\n",
    "\tdef __init__(self, num_epocs, train_data, test_data, num_features, learn_rate):\n",
    "\t\tself.train_data = train_data\n",
    "\t\tself.test_data = test_data \n",
    "\t\tself.num_features = num_features\n",
    "        # 输出数据维度，列数减去输入特征数量\n",
    "\t\tself.num_outputs = self.train_data.shape[1] - num_features\n",
    "        # 样本量\n",
    "\t\tself.num_train = self.train_data.shape[0]\n",
    "\t\tself.w = np.random.uniform(-0.5, 0.5, num_features)  # in case one output class \n",
    "\t\tself.b = np.random.uniform(-0.5, 0.5, self.num_outputs) \n",
    "\t\tself.learn_rate = learn_rate\n",
    "\t\tself.max_epoch = num_epocs\n",
    "\t\tself.use_activation = SIGMOID #SIGMOID # 1 is  sigmoid , 2 is step, 3 is linear \n",
    "        # 用于记录偏导数\n",
    "\t\tself.out_delta = np.zeros(self.num_outputs)\n",
    "\n",
    "\t\tprint(self.w, ' self.w init') \n",
    "\t\tprint(self.b, ' self.b init') \n",
    "\t\tprint(self.out_delta, ' outdel init')\n",
    "\n",
    "\n",
    "    # 根据非激活值计算激活值\n",
    "\tdef activation_func(self,z_vec):\n",
    "\t\tif self.use_activation == SIGMOID:\n",
    "\t\t\ty =  1 / (1 + np.exp(z_vec)) # sigmoid/logistic\n",
    "\t\telif self.use_activation == STEP:\n",
    "\t\t\ty = (z_vec > 0).astype(int) # if greater than 0, use 1, else 0\n",
    "\t\t\t#https://stackoverflow.com/questions/32726701/convert-real-valued-numpy-array-to-binary-array-by-sign\n",
    "\t\telse:\n",
    "\t\t\ty = z_vec\n",
    "\t\treturn y\n",
    " \n",
    "    # 计算y的输出值\n",
    "\tdef predict(self, x_vec ): \n",
    "\t\tz_vec = x_vec.dot(self.w) - self.b \n",
    "\t\toutput = self.activation_func(z_vec) # Output  \n",
    "\t\treturn output\n",
    "\t\n",
    "\t# 计算梯度 （已修正）\n",
    "    # 预测值减实际值：梯度， 实际值减预测值：负梯度\n",
    "\tdef gradient(self, x_vec, output, actual):   \n",
    "\t\tif self.use_activation == SIGMOID :\n",
    "\t\t\tout_delta =   (output - actual)*(output*(1-output)) \n",
    "\t\telse: # for linear and step function  \n",
    "\t\t\tout_delta =   (output - actual) \n",
    "\t\treturn out_delta\n",
    "\n",
    "\t# 更新参数：这里有问题，正确写法是改成-=\n",
    "\tdef update(self, x_vec, output, actual):      \n",
    "\t\tself.w+= self.learn_rate *( x_vec *  self.out_delta)\n",
    "\t\tself.b+=  (1 * self.learn_rate * self.out_delta)\n",
    " \n",
    "\t# 计算 SSE\n",
    "    # 对于分类问题，这里的计算 将概率与实际值之差 视为伪残差\n",
    "\tdef squared_error(self, prediction, actual):\n",
    "\t\treturn  np.sum(np.square(prediction - actual))/prediction.shape[0]# to cater more in one output/class\n",
    " \n",
    "\n",
    "\t# 评估模型\n",
    "\tdef test_model(self, data, tolerance):  \n",
    "\n",
    "\t\tnum_instances = data.shape[0]\n",
    "\n",
    "\t\tclass_perf = 0\n",
    "\t\tsum_sqer = 0   \n",
    "        \n",
    "        #循环遍历每一个样本\n",
    "\t\tfor s in range(0, num_instances):\t\n",
    "\n",
    "\t\t\tinput_instance  =  self.train_data[s,0:self.num_features] \n",
    "\t\t\tactual  = self.train_data[s,self.num_features:]  \n",
    "\t\t\tprediction = self.predict(input_instance)\n",
    "\t\t\tsum_sqer += self.squared_error(prediction, actual)\n",
    "\n",
    "\t\t\t# 设置分类概率阈值\n",
    "\t\t\tpred_binary = np.where(prediction > (1 - tolerance), 1, 0)\n",
    "\n",
    "\t\t\tprint(s, actual, prediction, pred_binary, sum_sqer, ' s, actual, prediction, sum_sqer')\n",
    "\n",
    " \n",
    "\t\t\t# 预测正确 +1\n",
    "\t\t\tif( (actual==pred_binary).all()):\n",
    "\t\t\t\tclass_perf =  class_perf +1   \n",
    "\n",
    "\t\trmse = np.sqrt(sum_sqer/num_instances)\n",
    "\n",
    "\t\tpercentage_correct = float(class_perf/num_instances) * 100 \n",
    "\n",
    "\t\tprint(percentage_correct, rmse,  ' class_perf, rmse') \n",
    "\t\t# note RMSE is not a good measure for multi-class probs\n",
    "\n",
    "\t\treturn ( rmse, percentage_correct)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\tdef SGD(self):   \n",
    "\t\t\n",
    "\t\t\tepoch = 0 \n",
    "\t\t\tshuffle = True\n",
    "\n",
    "\t\t\twhile  epoch < self.max_epoch:\n",
    "\t\t\t\tsum_sqer = 0\n",
    "\t\t\t\tfor s in range(0, self.num_train): \n",
    "\n",
    "\t\t\t\t\tif shuffle ==True:\n",
    "\t\t\t\t\t\ti = random.randint(0, self.num_train-1)\n",
    "\n",
    "\t\t\t\t\tinput_instance  =  self.train_data[i,0:self.num_features]  \n",
    "\t\t\t\t\tactual  = self.train_data[i,self.num_features:]  \n",
    "\t\t\t\t\tprediction = self.predict(input_instance) \n",
    "\t\t\t\t\tsum_sqer += self.squared_error(prediction, actual)\n",
    "\t\t\t\t\tself.out_delta = self.gradient( input_instance, prediction, actual)    # major difference when compared to GD\n",
    "\t\t\t\t\t#print(input_instance, prediction, actual, s, sum_sqer)\n",
    "                    \n",
    "                    # 使用梯度，更新参数\n",
    "\t\t\t\t\tself.update(input_instance, prediction, actual)\n",
    "\n",
    "\t\t\t\n",
    "\t\t\t\tprint(epoch, sum_sqer, self.w, self.b)\n",
    "\t\t\t\tepoch=epoch+1  \n",
    "\n",
    "\t\t\trmse_train, train_perc = self.test_model(self.train_data, 0.3) \n",
    "\t\t\trmse_test =0\n",
    "\t\t\ttest_perc =0\n",
    "\t\t\t#rmse_test, test_perc = self.test_model(self.test_data, 0.3)\n",
    "  \n",
    "\t\t\treturn (train_perc, test_perc, rmse_train, rmse_test) \n",
    "\t\t\t\t\n",
    "\t# 梯度下降\n",
    "\tdef GD(self):   \n",
    "\t\t\n",
    "\t\t\tepoch = 0 \n",
    "\t\t\twhile  epoch < self.max_epoch:\n",
    "\t\t\t\tsum_sqer = 0\n",
    "\t\t\t\tfor s in range(0, self.num_train): \n",
    "\t\t\t\t\tinput_instance  =  self.train_data[s,0:self.num_features]  \n",
    "\t\t\t\t\tactual  = self.train_data[s,self.num_features:]   \n",
    "\t\t\t\t\tprediction = self.predict(input_instance) \n",
    "\t\t\t\t\tsum_sqer += self.squared_error(prediction, actual) \n",
    "\t\t\t\t\tself.out_delta+= self.gradient( input_instance, prediction, actual)    # this is major difference when compared with SGD\n",
    "\n",
    "\t\t\t\t\t#print(input_instance, prediction, actual, s, sum_sqer)\n",
    "                \n",
    "\t\t\t\t\t# 使用梯度，更新参数\n",
    "\t\t\t\t\tself.update(input_instance, prediction, actual)\n",
    "\n",
    "\t\t\t\n",
    "\t\t\t\tprint(epoch, sum_sqer, self.w, self.b)\n",
    "\t\t\t\tepoch=epoch+1  \n",
    "\n",
    "\t\t\trmse_train, train_perc = self.test_model(self.train_data, 0.3) \n",
    "\t\t\trmse_test =0\n",
    "\t\t\ttest_perc =0\n",
    "\t\t\t#rmse_test, test_perc = self.test_model(self.test_data, 0.3)\n",
    "  \n",
    "\t\t\treturn (train_perc, test_perc, rmse_train, rmse_test) \n",
    "\t\t\t\t\n",
    "\t\n",
    " \n",
    "\n",
    "#------------------------------------------------------------------\n",
    "#MAIN\n",
    "\n",
    "\n",
    "\n",
    "def main(): \n",
    "\n",
    "\trandom.seed()\n",
    "\t \n",
    "\n",
    "\t \n",
    "\tdataset = [[2.7810836,2.550537003,0],\n",
    "\t\t[1.465489372,2.362125076,0],\n",
    "\t\t[3.396561688,4.400293529,0],\n",
    "\t\t[1.38807019,1.850220317,0],\n",
    "\t\t[3.06407232,3.005305973,0],\n",
    "\t\t[7.627531214,2.759262235,1],\n",
    "\t\t[5.332441248,2.088626775,1],\n",
    "\t\t[6.922596716,1.77106367,1],\n",
    "\t\t[8.675418651,-0.242068655,1],\n",
    "\t\t[7.673756466,3.508563011,1]]\n",
    "\n",
    "\n",
    "\ttrain_data = np.asarray(dataset) # convert list data to numpy\n",
    "\ttest_data = train_data\n",
    "\n",
    "\t \n",
    "\n",
    "\tlearn_rate = 0.3\n",
    "\tnum_features = 2\n",
    "\tnum_epocs = 20\n",
    "\n",
    "\tprint(train_data)\n",
    "\t \n",
    "\n",
    "\tlreg = logistic_regression(num_epocs, train_data, test_data, num_features, learn_rate)\n",
    "\t(train_perc, test_perc, rmse_train, rmse_test) = lreg.SGD()\n",
    "\t(train_perc, test_perc, rmse_train, rmse_test) = lreg.GD() \n",
    "\t \n",
    "\n",
    "\t#-------------------------------\n",
    "\t#xor data\n",
    "\n",
    "\n",
    "\txor_dataset= [[0,0,0],\n",
    "\t\t[0,1,1],\n",
    "\t\t[1,0,1],\n",
    "\t\t[1,1,0] ]\n",
    "\n",
    "\txor_data = np.asarray(xor_dataset) # convert list data to numpy\n",
    "\n",
    "\n",
    "\n",
    "\tnum_epocs = 20\n",
    "\tlearn_rate = 0.9\n",
    "\tnum_features = 2\n",
    "\n",
    "\tlreg = logistic_regression(num_epocs, xor_data, xor_data, num_features, learn_rate)\n",
    "\t(train_perc, test_perc, rmse_train, rmse_test) = lreg.SGD()\n",
    "\t(train_perc, test_perc, rmse_train, rmse_test) = lreg.GD() \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\": main()"
   ],
   "id": "815e87e68ae74f64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# LogLoss计算\n",
    "\n",
    "import numpy as np\n",
    "# 对数损失计算函数\n",
    "def loss(h, y):\n",
    "    return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "\n",
    "# 下面是例子：用这个函数做了两个计算\n",
    "h= np.random.rand(5)\n",
    "print(h, ' h')\n",
    "y= np.random.rand(5)\n",
    "print(y, ' y')\n",
    "  \n",
    "log_loss = loss(h, y) # case of regression or prediction problem\n",
    "print(log_loss)\n",
    "\n",
    "y_ = np.ones(5)\n",
    "print(y_, ' y_')\n",
    "log_loss = loss(h, y_) # case of classification problem (assume class one 1s)\n",
    "print(log_loss)"
   ],
   "id": "9f01979d40f34663",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Week 3",
   "id": "639cd56b187a8867"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#https://gist.githubusercontent.com/Thomascountz/77670d1fd621364bc41a7094563a7b9c/raw/39091aea4beb7bd33e7c492bdd8b1c3a344ca594/perceptron.py\n",
    "# Copyright (c) 2018 Thomas Countz\n",
    "\n",
    "import numpy as np\n",
    "'''\n",
    "这段代码实现了一个简单的感知器模型，用来训练和预测逻辑操作。以下是它的主要功能：\n",
    "\n",
    "定义了一个感知器类 (Perceptron)：\n",
    "\n",
    "初始化方法 (__init__) 接收输入特征的数量、阈值（用于循环次数）以及学习率。\n",
    "weights 表示权重向量，初始时全为零。\n",
    "predict 方法：\n",
    "\n",
    "计算输入数据的加权和（包括偏置），并基于阈值判断输出（激活函数）。\n",
    "输出为1或0，表示激活或不激活。\n",
    "train 方法：\n",
    "\n",
    "使用给定的训练数据和标签来训练模型。\n",
    "对于每一个训练样本，预测输出值，然后根据真实标签进行权重的更新。\n",
    "使用感知器模型训练一个简单的逻辑门：\n",
    "\n",
    "training_inputs 是逻辑门的输入，例如 [1, 1], [1, 0], [0, 1], [0, 0]。\n",
    "labels 是目标输出，例如 [1, 0, 0, 0] 表示一个与门 (AND gate) 的输出。\n",
    "创建感知器对象并训练模型，然后使用训练好的模型进行预测，打印出结果。\n",
    "\n",
    "简单来说，这段代码实现了一个基于感知器的逻辑门分类器（例如 AND 或 XOR），通过训练感知器来对输入做出预测。\n",
    "'''\n",
    "\n",
    "class Perceptron(object):\n",
    "\n",
    "    def __init__(self, no_of_inputs, threshold, learning_rate):\n",
    "        self.threshold = threshold\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = np.zeros(no_of_inputs + 1)\n",
    "           \n",
    "    def predict(self, inputs):\n",
    "        summation = np.dot(inputs, self.weights[1:]) + self.weights[0]\n",
    "        if summation > 0:\n",
    "          activation = 1\n",
    "        else:\n",
    "          activation = 0            \n",
    "        return activation\n",
    "\n",
    "    def train(self, training_inputs, labels):\n",
    "        for _ in range(self.threshold):\n",
    "\n",
    "            for inputs, label in zip(training_inputs, labels):\n",
    "                prediction = self.predict(inputs)\n",
    "                #print(prediction, label)\n",
    "                self.weights[1:] += self.learning_rate * (label - prediction) * inputs\n",
    "                self.weights[0] += self.learning_rate * (label - prediction) #bias\n",
    "\n",
    "\n",
    "# set the dataset inputs\n",
    "# AND gate \n",
    "\n",
    "training_inputs = []\n",
    "training_inputs.append(np.array([1, 1]))\n",
    "training_inputs.append(np.array([1, 0]))\n",
    "training_inputs.append(np.array([0, 1]))\n",
    "training_inputs.append(np.array([0, 0]))\n",
    "\n",
    "# set the dataset class labels\n",
    "labels = np.array([1, 0, 0, 0])# AND\n",
    "#labels = np.array([1, 0, 0, 1]) #XOR\n",
    "#labels = np.array([1, 1, 1, 0]) # OR\n",
    "\n",
    "no_of_inputs = 2\n",
    "threshold=100\n",
    "learning_rate=0.01\n",
    "\n",
    "# set the class and train\n",
    "perceptron = Perceptron(no_of_inputs, threshold, learning_rate)\n",
    "perceptron.train(training_inputs, labels)\n",
    "\n",
    "# now test trained percepton\n",
    "inputs = np.array([1, 1])\n",
    "output = perceptron.predict(inputs) \n",
    "print(output, ' for input [1, 1]' ) \n",
    "\n",
    "inputs = np.array([0, 1])\n",
    "output = perceptron.predict(inputs) \n",
    "print(output, ' for input [0, 1]' ) "
   ],
   "id": "2171ddc58dfe28f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Topo = [3,4, 2]\n",
    "\n",
    "'''这段代码定义了一个简单的多层前馈神经网络（MLP）类 Network，实现了神经网络的初始化过程，包括网络的拓扑结构、权重和偏置的随机初始化等。以下是代码主要部分的功能：\n",
    "\n",
    "类 Network 的初始化方法 (__init__):\n",
    "\n",
    "Topo：网络的拓扑结构（例如 [3, 4, 2] 表示网络有 3 个输入节点，4 个隐藏层节点，和 2 个输出节点）。\n",
    "Train 和 Test：训练数据和测试数据。\n",
    "MaxTime：最大训练轮数（epocs）。\n",
    "Samples：样本数量。\n",
    "MinPer：最小的性能要求，用于终止训练的条件之一。\n",
    "learnRate：学习率，用于权重更新时的步长控制。\n",
    "初始化网络的权重和偏置:\n",
    "\n",
    "W1：输入层到隐藏层的权重矩阵，维度为 (Topo[0], Topo[1])，随机初始化在 [-0.5, 0.5] 之间。\n",
    "B1：隐藏层的偏置，维度为 (1, Topo[1])，随机初始化在 [-0.5, 0.5] 之间。\n",
    "W2：隐藏层到输出层的权重矩阵，维度为 (Topo[1], Topo[2])，随机初始化在 [-0.5, 0.5] 之间。\n",
    "B2：输出层的偏置，维度为 (1, Topo[2])，随机初始化在 [-0.5, 0.5] 之间。\n",
    "BestW1、BestB1、BestW2、BestB2：用于保存最优的权重和偏置。\n",
    "隐藏层和输出层初始化:\n",
    "\n",
    "hidout：存储隐藏层的输出，初始化为全零。\n",
    "out：存储输出层的输出，初始化为全零。\n",
    "hid_delta 和 out_delta：分别用于存储隐藏层和输出层的误差项，初始化为全零。\n",
    "随机权重和偏置的初始化:\n",
    "\n",
    "使用 np.random.uniform(-0.5, 0.5, ...) 来随机初始化权重和偏置，使得它们的初始值在 [-0.5, 0.5] 之间。这样有助于避免所有权重都为同一个值的问题，提高模型的收敛性。'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import random\n",
    "import time\n",
    "\n",
    "class Network:\n",
    "\n",
    "\tdef __init__(self, Topo, Train, Test, MaxTime, Samples, MinPer, learnRate): \n",
    "\t\tself.Top  = Topo  # NN topology [input, hidden, output]\n",
    "\t\tself.Max = MaxTime # max epocs\n",
    "\t\tself.TrainData = Train\n",
    "\t\tself.TestData = Test\n",
    "\t\tself.NumSamples = Samples\n",
    "\n",
    "\t\tself.learn_rate  = learnRate\n",
    " \n",
    "\n",
    "\t\tself.minPerf = MinPer\n",
    "\t\t\n",
    "\t\t#initialize weights ( W1 W2 ) and bias ( b1 b2 ) of the network\n",
    "\t\tnp.random.seed() \n",
    "\t\tself.W1 = np.random.uniform(-0.5, 0.5, (self.Top[0] , self.Top[1]))  \n",
    "\t\t#print(self.W1,  ' self.W1')\n",
    "\t\tself.B1 = np.random.uniform(-0.5,0.5, (1, self.Top[1])  ) # bias first layer\n",
    "\t\t#print(self.B1, ' self.B1')\n",
    "\t\tself.BestB1 = self.B1\n",
    "\t\tself.BestW1 = self.W1 \n",
    "\t\tself.W2 = np.random.uniform(-0.5, 0.5, (self.Top[1] , self.Top[2]))   \n",
    "\t\tself.B2 = np.random.uniform(-0.5,0.5, (1,self.Top[2]))  # bias second layer\n",
    "\t\tself.BestB2 = self.B2\n",
    "\t\tself.BestW2 = self.W2 \n",
    "\t\tself.hidout = np.zeros(self.Top[1] ) # output of first hidden layer\n",
    "\t\tself.out = np.zeros(self.Top[2]) #  output last layer\n",
    "\n",
    "\t\tself.hid_delta = np.zeros(self.Top[1] ) # output of first hidden layer\n",
    "\t\tself.out_delta = np.zeros(self.Top[2]) #  output last layer"
   ],
   "id": "2d2eba881582b712",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Week 4",
   "id": "ecadc849d2638c8f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Source: https://www.python-course.eu/neural_networks_with_scikit.php\n",
    "'''\n",
    "这段代码实现了一个神经网络的反向传播算法，用于计算误差并更新网络的权重和偏置。以下是具体解释：\n",
    "\n",
    "BackwardPass 方法：\n",
    "\n",
    "参数：\n",
    "input_vec：输入向量，表示当前样本输入到神经网络的特征。\n",
    "desired：目标值，表示当前样本的真实标签。\n",
    "输出层误差计算 (out_delta)：\n",
    "\n",
    "out_delta = (desired - self.out) * (self.out * (1 - self.out))：\n",
    "desired - self.out：计算输出误差，即目标输出与神经网络当前预测值的差异。\n",
    "self.out * (1 - self.out)：对输出层进行激活函数的导数计算，这里假设使用的是 Sigmoid 激活函数，其导数为 f(x) * (1 - f(x))。\n",
    "out_delta 表示输出层的误差项，反映了神经网络的输出与期望输出之间的偏差。\n",
    "隐藏层误差计算 (hid_delta)：\n",
    "\n",
    "hid_delta = out_delta.dot(self.W2.T) * (self.hidout * (1 - self.hidout))：\n",
    "使用 out_delta 和隐藏层到输出层的权重矩阵 self.W2 来计算隐藏层的误差项。\n",
    "out_delta.dot(self.W2.T)：将输出层误差反向传播到隐藏层，dot 表示矩阵乘法。\n",
    "self.hidout * (1 - self.hidout)：对隐藏层的激活值进行激活函数的导数计算，这里同样假设使用的是 Sigmoid 激活函数。\n",
    "hid_delta 表示隐藏层的误差项，反映了隐藏层节点对最终输出误差的贡献。\n",
    "更新权重和偏置：\n",
    "\n",
    "更新输出层权重和偏置：\n",
    "self.W2 += self.hidout.T.dot(out_delta) * self.learn_rate：使用隐藏层的输出和输出层误差项来更新 W2，即隐藏层到输出层的权重。\n",
    "self.B2 += (-1 * self.learn_rate * out_delta)：更新输出层的偏置 B2，调整方向与学习率有关。\n",
    "更新隐藏层权重和偏置：\n",
    "self.W1 += input_vec.T.dot(hid_delta) * self.learn_rate：使用输入向量和隐藏层误差项来更新 W1，即输入层到隐藏层的权重。\n",
    "self.B1 += (-1 * self.learn_rate * hid_delta)：更新隐藏层的偏置 B1。\n",
    "学习率的作用：\n",
    "\n",
    "学习率 self.learn_rate 控制每次更新的步长大小，避免过大的权重更新导致模型发散。\n",
    "'''\n",
    "\n",
    "#FNN Version Two\n",
    "\tdef BackwardPass(self, input_vec, desired):   \n",
    "\t\tout_delta =   (desired - self.out)*(self.out*(1-self.out))  \n",
    "\t\thid_delta = out_delta.dot(self.W2.T) * (self.hidout * (1-self.hidout)) #https://www.tutorialspoint.com/numpy/numpy_dot.htm  https://www.geeksforgeeks.org/numpy-dot-python/\n",
    "  \n",
    "\t\tself.W2+= self.hidout.T.dot(out_delta) * self.learn_rate\n",
    "\t\tself.B2+=  (-1 * self.learn_rate * out_delta)\n",
    "\n",
    "\t\tself.W1 += (input_vec.T.dot(hid_delta) * self.learn_rate) \n",
    "\t\tself.B1+=  (-1 * self.learn_rate * hid_delta) "
   ],
   "id": "1748b0c0f990a0ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''\n",
    "这段代码定义了一个函数 BackwardPass，用于实现一个简单神经网络的反向传播（Backpropagation），它是训练神经网络的关键步骤。函数通过调整权重和偏置（weights and biases）来最小化损失。下面是对代码的详细解释：\n",
    "\n",
    "函数定义和输入参数：\n",
    "\n",
    "self：引用类实例，用于访问对象的属性。\n",
    "input_vec：输入向量，即用于前向传播的输入数据。\n",
    "desired：期望的输出（真实标签），用于计算误差。\n",
    "输出层误差计算 (out_delta)：\n",
    "\n",
    "out_delta = (desired - self.out) * (self.out * (1 - self.out))：\n",
    "这里 (desired - self.out) 表示输出层的误差。\n",
    "self.out * (1 - self.out) 是 Sigmoid 激活函数的导数。\n",
    "out_delta 表示输出层的误差项，用于计算梯度。\n",
    "隐藏层误差计算 (hid_delta)：\n",
    "\n",
    "hid_delta = out_delta.dot(self.W2.T) * (self.hidout * (1 - self.hidout))：\n",
    "out_delta.dot(self.W2.T) 计算输出层误差对隐藏层的影响（反向传播）。\n",
    "self.hidout * (1 - self.hidout) 是隐藏层激活函数（Sigmoid）的导数。\n",
    "hid_delta 表示隐藏层的误差项。\n",
    "更新权重和偏置（根据是否使用动量）：\n",
    "\n",
    "如果 self.vanilla == True，即没有动量：\n",
    "\n",
    "更新输出层权重 W2：self.W2 += self.hidout.T.dot(out_delta) * self.learn_rate\n",
    "使用隐藏层输出与输出层误差计算梯度，再乘以学习率 learn_rate。\n",
    "更新输出层偏置 B2：self.B2 += (-1 * self.learn_rate * out_delta)。\n",
    "更新隐藏层权重 W1：self.W1 += input_vec.T.dot(hid_delta) * self.learn_rate。\n",
    "更新隐藏层偏置 B1：self.B1 += (-1 * self.learn_rate * hid_delta)。\n",
    "如果使用动量：\n",
    "\n",
    "使用 self.momenRate 和之前的权重、偏置值来加速收敛并避免震荡。\n",
    "使用动量来更新权重和偏置时：\n",
    "先将当前权重和偏置保存在 v2, v1, b2, b1 中。\n",
    "更新权重时，不仅考虑当前的梯度，还加入了一部分的动量（即之前的权重变化）。\n",
    "'''\n",
    "\n",
    "def BackwardPass(self, input_vec, desired):   \n",
    "\t\tout_delta =   (desired - self.out)*(self.out*(1-self.out))  \n",
    "\t\thid_delta = out_delta.dot(self.W2.T) * (self.hidout * (1-self.hidout)) \n",
    "\t\t#https://www.tutorialspoint.com/numpy/numpy_dot.htm  https://www.geeksforgeeks.org/numpy-dot-python/\n",
    "  \n",
    "\t\tif self.vanilla == True: #no momentum \n",
    "\t\t\tself.W2+= self.hidout.T.dot(out_delta) * self.learn_rate\n",
    "\t\t\tself.B2+=  (-1 * self.learn_rate * out_delta)\n",
    "\n",
    "\t\t\tself.W1 += (input_vec.T.dot(hid_delta) * self.learn_rate) \n",
    "\t\t\tself.B1+=  (-1 * self.learn_rate * hid_delta) \n",
    "\t\telse: # use momentum\n",
    "\t\t\tv2 = self.W2.copy() #save previous weights http://cs231n.github.io/neural-networks-3/#sgd\n",
    "\t\t\tv1 = self.W1.copy()\n",
    "\t\t\tb2 = self.B2.copy()\n",
    "\t\t\tb1 = self.B1.copy()\n",
    "\n",
    "\t\t\tself.W2+= ( v2 *self.momenRate) + (self.hidout.T.dot(out_delta) * self.learn_rate)       # velocity update\n",
    "\t\t\tself.W1 += ( v1 *self.momenRate) + (input_vec.T.dot(hid_delta) * self.learn_rate)   \n",
    "\t\t\tself.B2+= ( b2 *self.momenRate) + (-1 * self.learn_rate * out_delta)       # velocity update\n",
    "\t\t\tself.B1 += ( b1 *self.momenRate) + (-1 * self.learn_rate * hid_delta)   "
   ],
   "id": "6b310916046f5eac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "#useStocastic = True # False for vanilla BP with SGD (no shuffle of data). # True for BP with SGD (shuffle of data at every epoch) \n",
    "\n",
    "#updateStyle = False # True for Vanilla SGD, False for momentum SGD\n",
    "\n",
    "def BP_GD(self, trainTolerance):  \n",
    "\t\tInput = np.zeros((1, self.Top[0])) # Temp hold input\n",
    "\t\tDesired = np.zeros((1, self.Top[2])) \n",
    "\n",
    "\t\t#minibatchsize = int(0.1* self.TrainData.shape[0]) # Choose a mini-batch size for SGD - optional exercise to implement this\n",
    "\n",
    "\t\tEr = [] \n",
    "\t\tepoch = 0\n",
    "\t\tbestRMSE= 10000 # Assign a large number in begining to maintain best (lowest RMSE)\n",
    "\t\tbestTrain = 0\n",
    "\t\twhile  epoch < self.Max and bestTrain < self.minPerf :\n",
    "\t\t\tsse = 0\n",
    "\n",
    "\t\t\tfor s in range(0, self.TrainData.shape[0]):\n",
    "\t\t\t\tif(self.stocasticGD==True):   \n",
    "\t\t\t\t\tpat = random.randint(0, self.TrainData.shape[0]-1) \n",
    "\t\t\t\t\t# Data shuffle in SGD: https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.random.randint.html\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tpat = s # no data shuffle in SGD\n",
    "\t\t\n",
    "\t\t\t\tInput[:]  =  self.TrainData[pat,0:self.Top[0]]  \n",
    "\t\t\t\tDesired[:]  = self.TrainData[pat,self.Top[0]:]  \n",
    "\n",
    "\t\t\t\tself.ForwardPass(Input)  \n",
    "\t\t\t\tself.BackwardPass(Input ,Desired)\n",
    "\t\t\t\tsse = sse+ self.sampleEr(Desired)\n",
    "\t\t\t \n",
    "\t\t\trmse = np.sqrt(sse/self.TrainData.shape[0]*self.Top[2])\n",
    "\n",
    "\t\t\tif rmse < bestRMSE:\n",
    "\t\t\t\t bestRMSE = rmse\n",
    "\t\t\t\t self.saveKnowledge() \n",
    "\t\t\t\t (bestRMSE,bestTrain) = self.TestNetwork(self.TrainData,   trainTolerance)\n",
    "\t\t\t\t #Print(bestRMSE, bestTrain)\n",
    "\n",
    "\t\t\tEr = np.append(Er, rmse)\n",
    "\t\t\t\n",
    "\t\t\tepoch=epoch+1  \n",
    "\n",
    "\t\treturn (Er,bestRMSE, bestTrain, epoch) \n"
   ],
   "id": "1f887c7bf05781dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# gradient descent optimization with adam for a two-dimensional test function\n",
    "\n",
    "'''这段代码实现了使用Adam优化算法来最小化一个简单的二维目标函数f(x, y) = x^2 + y^2。Adam是一种改进的梯度下降算法，它结合了动量（momentum）和自适应学习率的方法来加速优化。\n",
    "\n",
    "以下是代码的主要步骤解释：\n",
    "\n",
    "目标函数：定义了一个简单的目标函数objective(x, y)，其值是x和y的平方和。这是一个典型的二次函数，形状为抛物面，最小值位于原点(0, 0)。\n",
    "\n",
    "导数函数：定义了目标函数的导数（梯度）derivative(x, y)，返回的是每个变量的偏导数。对于目标函数来说，偏导数分别是2x和2y。\n",
    "\n",
    "Adam优化算法：\n",
    "\n",
    "函数adam用于实现Adam优化算法。\n",
    "首先随机生成一个初始点x，在给定范围内选取。\n",
    "初始化动量m和平方梯度v，用于存储一阶和二阶动量。\n",
    "迭代n_iter次，每次计算梯度g，然后更新动量m和平方梯度v。\n",
    "使用修正后的动量mhat和vhat来更新每个变量的值x，使其逐步靠近函数的最小值。\n",
    "每次迭代后输出当前点的函数值，以查看优化进度。\n",
    "参数设置：\n",
    "\n",
    "设置搜索范围bounds为[-1, 1]，即每个变量的初始值在-1到1之间。\n",
    "n_iter为60，表示算法迭代60次。\n",
    "alpha为步长（学习率），beta1和beta2分别为动量和均方梯度的指数加权平均系数。\n",
    "输出：\n",
    "\n",
    "在每次迭代中，代码会打印当前的迭代次数、当前点的位置以及目标函数值。\n",
    "最后输出优化得到的点及其对应的函数值。\n",
    "Adam算法通过结合动量和自适应学习率，能够在一定程度上加快梯度下降的收敛速度，并防止陷入局部极小值。这段代码演示了如何从随机初始点开始，通过多次迭代不断逼近目标函数的最小值。'''\n",
    "\n",
    "from math import sqrt\n",
    "from numpy import asarray\n",
    "from numpy.random import rand\n",
    "from numpy.random import seed\n",
    " \n",
    "# objective function\n",
    "def objective(x, y):\n",
    "\treturn x**2.0 + y**2.0\n",
    " \n",
    "# derivative of objective function\n",
    "def derivative(x, y):\n",
    "\treturn asarray([x * 2.0, y * 2.0])\n",
    " \n",
    "# gradient descent algorithm with adam\n",
    "def adam(objective, derivative, bounds, n_iter, alpha, beta1, beta2, eps=1e-8):\n",
    "\t# generate an initial point\n",
    "\tx = bounds[:, 0] + rand(len(bounds)) * (bounds[:, 1] - bounds[:, 0])\n",
    "\tscore = objective(x[0], x[1])\n",
    "\t# initialize first and second moments\n",
    "\tm = [0.0 for _ in range(bounds.shape[0])]\n",
    "\tv = [0.0 for _ in range(bounds.shape[0])]\n",
    "\t# run the gradient descent updates\n",
    "\tfor t in range(n_iter):\n",
    "\t\t# calculate gradient g(t)\n",
    "\t\tg = derivative(x[0], x[1])\n",
    "\t\t# build a solution one variable at a time\n",
    "\t\tfor i in range(x.shape[0]):\n",
    "\t\t\t# m(t) = beta1 * m(t-1) + (1 - beta1) * g(t)\n",
    "\t\t\tm[i] = beta1 * m[i] + (1.0 - beta1) * g[i]\n",
    "\t\t\t# v(t) = beta2 * v(t-1) + (1 - beta2) * g(t)^2\n",
    "\t\t\tv[i] = beta2 * v[i] + (1.0 - beta2) * g[i]**2\n",
    "\t\t\t# mhat(t) = m(t) / (1 - beta1(t))\n",
    "\t\t\tmhat = m[i] / (1.0 - beta1**(t+1))\n",
    "\t\t\t# vhat(t) = v(t) / (1 - beta2(t))\n",
    "\t\t\tvhat = v[i] / (1.0 - beta2**(t+1))\n",
    "\t\t\t# x(t) = x(t-1) - alpha * mhat(t) / (sqrt(vhat(t)) + eps)\n",
    "\t\t\tx[i] = x[i] - alpha * mhat / (sqrt(vhat) + eps)\n",
    "\t\t# evaluate candidate point\n",
    "\t\tscore = objective(x[0], x[1])\n",
    "\t\t# report progress\n",
    "\t\tprint('>%d f(%s) = %.5f' % (t, x, score))\n",
    "\treturn [x, score]\n",
    " \n",
    "# seed the pseudo random number generator\n",
    "seed(1)\n",
    "#source: https://machinelearningmastery.com/adam-optimization-from-scratch/\n",
    "\n",
    "# define range for input\n",
    "bounds = asarray([[-1.0, 1.0], [-1.0, 1.0]])\n",
    "# define the total iterations\n",
    "n_iter = 60\n",
    "# steps size\n",
    "alpha = 0.02\n",
    "# factor for average gradient\n",
    "beta1 = 0.8\n",
    "# factor for average squared gradient\n",
    "beta2 = 0.999\n",
    "# perform the gradient descent search with adam\n",
    "best, score = adam(objective, derivative, bounds, n_iter, alpha, beta1, beta2)\n",
    "print('Done!')\n",
    "print('f(%s) = %f' % (best, score))"
   ],
   "id": "ee75f0b597eb6bf2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Rohitash Chandra, 2021 c.rohitash@gmail.conm\n",
    "'''\n",
    "这段代码实现了一个简单的深度神经网络类，包含多个全连接层。代码主要分为两个部分：Layers类和Network类，分别代表神经网络的各层以及整个神经网络的结构和训练过程。\n",
    "\n",
    "下面是代码的详细解释：\n",
    "\n",
    "1. Layers类\n",
    "Layers类用于表示神经网络中的一个层。其目的是初始化每个神经网络层的权重、偏置以及一些用于存储输出和梯度的变量。\n",
    "\n",
    "初始化方法 (__init__)：\n",
    "参数first是输入神经元的数量，second是输出神经元的数量。\n",
    "权重 (weights)：使用np.random.uniform(-0.5, 0.5, (first , second))随机初始化一个形状为(first, second)的权重矩阵，值在-0.5到0.5之间。\n",
    "偏置 (bias)：偏置矩阵也被随机初始化为(-0.5, 0.5)的值，形状为(1, second)。\n",
    "输出 (output)和梯度 (gradient)：用于存储这一层的输出和反向传播中的梯度，初始值为0。\n",
    "2. Network类\n",
    "Network类表示整个神经网络的结构和训练过程。\n",
    "\n",
    "初始化方法 (__init__)：\n",
    "topology：表示网络的拓扑结构，即每层的神经元数量，例如[4, 5, 3]表示输入层有4个神经元，隐藏层有5个神经元，输出层有3个神经元。\n",
    "x_train、x_test、y_train、y_test：分别是训练集和测试集的特征和标签。\n",
    "max_epocs：最大训练轮数（epochs）。\n",
    "min_error：定义的最小误差，用于决定训练是否终止。\n",
    "learn_rate：用于随机梯度下降（SGD）的学习率。\n",
    "Adam学习率 (adam_learnrate)：初始化为0.05，敏感于Adam优化算法。\n",
    "end_index：记录最后一层的索引，方便后续的操作。\n",
    "层的初始化：使用self.layer = [None]*20来预先创建20个可能的层（假设神经网络最多有20层），然后通过for循环根据topology初始化实际的层。\n",
    "第一个元素是一个特殊的层，用来存储输入特征。\n",
    "其余的层根据拓扑结构初始化，每层的输入大小等于前一层的输出大小，输出大小等于当前层的神经元数量。\n",
    "'''\n",
    "#https://github.com/sydney-machine-learning/multilayerperceptron-sgd-adam/blob/main/fnn-multiplelayers.py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "from numpy import *\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "\n",
    "#Source: https://github.com/sydney-machine-learning/multilayerperceptron-sgd-adam/blob/main/fnn-multiplelayers.py\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Layers:\n",
    "\n",
    "\tdef __init__(self, first, second,adam_learnrate=None):  \n",
    "\t\t#self.number = first\n",
    "\n",
    "\t\tself.weights = np.random.uniform(-0.5, 0.5, (first , second))   \n",
    "\t\tself.bias = np.random.uniform(-0.5,0.5, (1, second))  # bias second layer\n",
    "\n",
    "\t\tself.output = np.zeros(second) # output of  layer \n",
    "\t\tself.gradient = np.zeros(second) # gradient of layer \n",
    " \n",
    "\n",
    "class Network:\n",
    "\n",
    "\tdef __init__(self, topology, x_train, x_test, y_train, y_test, max_epocs,   min_error, learn_rate): # this is called construtor\n",
    "\t\tself.topology  = topology   \n",
    "\n",
    "\t\tself.output_activationfunc = 'sigmoid' \n",
    "\n",
    "\t\tself.max_epocs = max_epocs # max epocs\n",
    "\t\t#self.TrainData = Train\n",
    "\t\t#self.TestData = Test\n",
    "\n",
    "\t\tself.x_train = x_train\n",
    "\t\tself.x_test = x_test\n",
    "\t\tself.y_train = y_train\n",
    "\t\tself.y_test = y_test\n",
    "\n",
    "\n",
    "\t\tself.num_samples =  x_train.shape[0] \n",
    "\n",
    "\t\tself.sgdlearn_rate  = learn_rate\n",
    " \n",
    "\n",
    "\t\tself.min_error = min_error \n",
    "\t\t \n",
    "\t\tnp.random.seed()   \n",
    "\n",
    "\t\tself.adam_learnrate = 0.05 #sensitive for adam\n",
    " \n",
    "\n",
    "\t\tself.end_index = len(self.topology)-1\n",
    "\n",
    "\n",
    "\t\tself.layer = [None]*20  # create list of Layers objects ( just max size of 20 for now - assuming a very deep neural network )\n",
    "\n",
    "\t\tprint(self.topology,  ' topology')\n",
    "\n",
    "\t\tself.layer[0] = Layers(1,1, 0) # this is just for layer where input features are stored\n",
    "\n",
    "\t\tfor n in range(1,  len(self.topology)):  \n",
    "\t\t\tself.layer[n] = Layers(self.topology[n-1],self.topology[n], self.adam_learnrate)"
   ],
   "id": "573c1bb002beed7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Week5",
   "id": "3ea841459d4f5fd8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''\n",
    "这段代码定义了一个MCMC类，用于实现基于马尔可夫链蒙特卡罗（MCMC）方法的神经网络训练和评估。MCMC是一种统计方法，用于从复杂的概率分布中采样，通常用于贝叶斯推理和神经网络的优化。\n",
    "\n",
    "以下是代码的详细解释：\n",
    "\n",
    "MCMC类\n",
    "1. 初始化方法 (__init__)\n",
    "samples：采样的数量，用于MCMC过程。\n",
    "topology：神经网络的拓扑结构，定义了输入、隐藏和输出层的神经元数量。\n",
    "traindata 和 testdata：训练和测试数据，用于模型评估。\n",
    "regression：如果为True，表示这是回归问题；如果为False，则表示是分类问题。\n",
    "random.seed()：用来初始化随机数生成器，以确保每次运行的结果不同。\n",
    "2. RMSE计算方法 (rmse)\n",
    "函数定义：rmse(self, predictions, targets)。\n",
    "计算预测值和真实目标值之间的均方根误差（RMSE），用于评估模型的性能。\n",
    "公式：np.sqrt(((predictions - targets) ** 2).mean())，通过计算误差平方的均值并取平方根得到RMSE。\n",
    "3. 似然函数 (likelihood_func)\n",
    "函数定义：likelihood_func(self, model, data, w, tausq)。\n",
    "该函数用于计算模型在给定权重w下的似然值。\n",
    "y：目标值，从数据集中提取。\n",
    "fx：通过模型的evaluate_proposal()函数使用当前权重w来计算模型的预测值。\n",
    "RMSE计算：调用前面定义的rmse方法计算预测的精度。\n",
    "损失计算：使用高斯似然函数，计算负对数似然损失。\n",
    "loss = -0.5 * np.log(2 * math.pi * tausq) - 0.5 * np.square(y - fx) / tausq。\n",
    "其中tausq表示噪声的方差。\n",
    "返回值：返回损失的总和、模型的预测值和RMSE精度。\n",
    "4. 先验似然函数 (prior_likelihood)\n",
    "函数定义：prior_likelihood(self, sigma_squared, nu_1, nu_2, w, tausq)。\n",
    "该函数计算模型参数w的先验似然值，用于贝叶斯推理中的先验分布。\n",
    "参数：\n",
    "sigma_squared：模型权重的方差，控制先验的分布宽度。\n",
    "nu_1 和 nu_2：用于计算逆伽马分布（inverse gamma distribution）的参数。\n",
    "w：神经网络的权重。\n",
    "tausq：输出的噪声方差。\n",
    "先验似然的计算：\n",
    "param = self.topology[0] + 1：计算模型参数的数量。\n",
    "部分1（多元正态分布部分）：计算多元正态分布的对数先验。\n",
    "part1 = -1 * (param / 2) * np.log(sigma_squared)：根据方差的对数，计算常数项。\n",
    "part2 = 1 / (2 * sigma_squared) * (sum(np.square(w)))：计算权重平方和的部分。\n",
    "multivariate_normal = part1 - part2：计算多元正态分布的对数先验。\n",
    "部分2（逆伽马分布部分）：\n",
    "inverse_gamma = -(1 + nu_1) * np.log(tausq) - (nu_2 / tausq)：计算逆伽马分布的对数先验。\n",
    "对数损失 (log_loss)：\n",
    "log_loss = multivariate_normal + inverse_gamma：将两个对数似然部分相加，得到总的先验似然值。\n",
    "返回值：返回计算得到的先验对数损失。\n",
    "'''\n",
    "class MCMC:\n",
    "\tdef __init__(self, samples, traindata, testdata, topology, regression):\n",
    "\t\tself.samples = samples  # NN topology [input, hidden, output]\n",
    "\t\tself.topology = topology  # max epocs\n",
    "\t\tself.traindata = traindata  #\n",
    "\t\tself.testdata = testdata\n",
    "\t\trandom.seed() \n",
    "\t\tself.regression = regression # False means classification\n",
    "\n",
    "\tdef rmse(self, predictions, targets):\n",
    "\t\treturn np.sqrt(((predictions - targets) ** 2).mean())\n",
    " \n",
    "\tdef likelihood_func(self, model, data, w, tausq):\n",
    "\t\ty = data[:, self.topology[0]]\n",
    "\t\tfx = model.evaluate_proposal(data, w) \n",
    "\t\taccuracy = self.rmse(fx, y) #RMSE \n",
    "\t\tloss = -0.5 * np.log(2 * math.pi * tausq) - 0.5 * np.square(y - fx) / tausq \n",
    "\t\treturn [np.sum(loss), fx, accuracy]\n",
    "\n",
    "\tdef prior_likelihood(self, sigma_squared, nu_1, nu_2, w, tausq): \n",
    "\t\tparam = self.topology[0]  + 1 # number of parameters in model\n",
    "\t\tpart1 = -1 * (param / 2) * np.log(sigma_squared)\n",
    "\t\tpart2 = 1 / (2 * sigma_squared) * (sum(np.square(w)))\n",
    "        multivariate_normal = part1 - part2\n",
    "        inverse_gamma = -(1 + nu_1) * np.log(tausq) - (nu_2 / tausq)\n",
    "\t\tlog_loss = multivariate_normal + inverge_gamma\n",
    "\t\treturn log_loss"
   ],
   "id": "7443ad636f08188f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    " # by R. Chandra\n",
    " #https://github.com/rohitash-chandra/Bayesian_logisticregression\n",
    "\n",
    "'''\n",
    "这段代码实现了一个简单的线性模型，用于回归或分类任务（如逻辑回归）。代码通过定义lin_model类，创建了一个模型，包含训练数据和测试数据的处理，以及前向传播和预测的实现。\n",
    "\n",
    "lin_model类解释\n",
    "lin_model类的作用是实现一个简单的线性模型，该模型可以用于回归或分类任务，具体取决于是否使用激活函数。\n",
    "\n",
    "1. 初始化方法 (__init__)\n",
    "num_epocs：训练的最大迭代次数（epochs）。\n",
    "train_data 和 test_data：分别是训练数据和测试数据。\n",
    "num_features：输入数据的特征数量。\n",
    "learn_rate：学习率，用于梯度更新。\n",
    "activation：是否使用激活函数。如果为False，则使用Sigmoid激活函数。\n",
    "初始化权重 (self.w) 和偏置 (self.b)：\n",
    "权重w初始化为在-0.5到0.5之间随机生成的值，大小为num_features。\n",
    "偏置b也是在-0.5到0.5之间随机生成的值，大小为输出的数量（即num_outputs）。\n",
    "数据的形状：\n",
    "self.num_outputs为输出类别的数量，等于训练数据列数减去特征的数量。\n",
    "self.num_train是训练数据的样本数量。\n",
    "2. 激活函数 (activation_func)\n",
    "函数定义：activation_func(self, z_vec)。\n",
    "如果self.use_activation为False，则使用Sigmoid函数：y = 1 / (1 + np.exp(z_vec))。\n",
    "如果self.use_activation为True，则不进行激活，直接输出输入值z_vec。\n",
    "返回激活后的输出值。\n",
    "3. 预测函数 (predict)\n",
    "函数定义：predict(self, x_vec)。\n",
    "计算过程：\n",
    "使用线性函数z_vec = x_vec.dot(self.w) - self.b计算输出。\n",
    "将结果传递给激活函数：output = self.activation_func(z_vec)。\n",
    "返回最终的输出output。\n",
    "4. 均方误差函数 (squared_error)\n",
    "函数定义：squared_error(self, prediction, actual)。\n",
    "计算过程：\n",
    "计算预测值与真实值之间的均方误差（MSE）：np.sum(np.square(prediction - actual))/prediction.shape[0]。\n",
    "返回误差值。均方误差用于衡量预测值与真实值之间的差异。\n",
    "5. 编码函数 (encode)\n",
    "函数定义：encode(self, w)。\n",
    "作用：将输入的权重w解码为模型的权重和偏置。\n",
    "self.w = w[0:self.num_features]：将输入的前num_features个值赋给模型的权重。\n",
    "self.b = w[self.num_features]：将权重数组的最后一个值赋给偏置b。\n",
    "6. 提案评估函数 (evaluate_proposal)\n",
    "函数定义：evaluate_proposal(self, data, w)。\n",
    "作用：通过给定的权重w对输入数据进行评估，并返回预测值。\n",
    "计算过程：\n",
    "首先使用encode(w)方法将输入权重解码为模型的权重和偏置。\n",
    "创建fx数组，用于存储每个样本的预测值。\n",
    "对每个样本进行预测：\n",
    "input_instance提取输入特征。\n",
    "使用predict(input_instance)计算模型对样本的预测值。\n",
    "将预测值存储在fx中。\n",
    "返回所有样本的预测值数组fx。\n",
    "代码的整体流程\n",
    "导入模块：导入了一些常用的库，包括numpy、math和matplotlib，用于数值计算、数学运算和绘图。\n",
    "lin_model类的定义：\n",
    "lin_model类用于创建一个线性模型，并初始化相应的参数。\n",
    "包含了前向传播的实现（predict方法）、激活函数（activation_func方法）、计算误差（squared_error方法）等。\n",
    "提供了权重的编码和评估提案的方法（encode和evaluate_proposal）。\n",
    "激活函数的选择：\n",
    "可以选择是否使用激活函数，如果使用，则采用Sigmoid激活函数，否则输出线性值。\n",
    "'''\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from math import exp\n",
    "\n",
    "class lin_model:\n",
    "\n",
    "\tdef __init__(self, num_epocs, train_data, test_data, num_features, learn_rate, activation):\n",
    "\t\tself.train_data = train_data\n",
    "\t\tself.test_data = test_data \n",
    "\t\tself.num_features = num_features\n",
    "\t\tself.num_outputs = self.train_data.shape[1] - num_features \n",
    "\t\tself.num_train = self.train_data.shape[0]\n",
    "\t\tself.w = np.random.uniform(-0.5, 0.5, num_features)  # in case one output class \n",
    "\t\tself.b = np.random.uniform(-0.5, 0.5, self.num_outputs) \n",
    "\t\tself.learn_rate = learn_rate\n",
    "\t\tself.max_epoch = num_epocs\n",
    "\t\tself.use_activation = activation #SIGMOID # 1 is  sigmoid , 2 is step, 3 is linear \n",
    "\t\tself.out_delta = np.zeros(self.num_outputs)\n",
    "\t\tself.activation = activation\n",
    " \n",
    "\tdef activation_func(self,z_vec):\n",
    "\t\tif self.use_activation == False:\n",
    "\t\t\ty =  1 / (1 + np.exp(z_vec)) # sigmoid/logistic\n",
    "\t\telse:\n",
    "\t\t\ty = z_vec \n",
    "\t\treturn y\n",
    "\n",
    "\tdef predict(self, x_vec ): \n",
    "\t\tz_vec = x_vec.dot(self.w) - self.b \n",
    "\t\toutput = self.activation_func(z_vec) # Output  \n",
    "\t\treturn output\n",
    "\t\n",
    "\n",
    "\n",
    "\tdef squared_error(self, prediction, actual):\n",
    "\t\treturn  np.sum(np.square(prediction - actual))/prediction.shape[0]# to cater more in one output/class\n",
    " \n",
    "\tdef encode(self, w): # get  the parameters and encode into the model\n",
    "\t\t \n",
    "\t\tself.w =  w[0:self.num_features]\n",
    "\t\tself.b = w[self.num_features] \n",
    "\n",
    "\tdef evaluate_proposal(self, data, w):  # BP with SGD (Stocastic BP)\n",
    "\n",
    "\t\tself.encode(w)  # method to encode w and b\n",
    "\t\tfx = np.zeros(data.shape[0]) \n",
    "\n",
    "\t\tfor s in range(0, data.shape[0]):  \n",
    "\t\t\t\ti = s #random.randint(0, data.shape[0]-1)  (we dont shuffle in this implementation)\n",
    "\t\t\t\tinput_instance  =  data[i,0:self.num_features]  \n",
    "\t\t\t\tactual  = data[i,self.num_features:]  \n",
    "\t\t\t\tprediction = self.predict(input_instance)  \n",
    "\t\t\t\tfx[s] = prediction\n",
    "\n",
    "\t\treturn fx"
   ],
   "id": "e21eeaf9d377b4f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''\n",
    "1. 初始化MCMC采样\n",
    "样本大小 (testsize, trainsize, samples)：\n",
    "\n",
    "testsize：测试集样本数量。\n",
    "trainsize：训练集样本数量。\n",
    "samples：采样次数，即需要从后验分布中采样多少组参数。\n",
    "数据划分 (x_test, x_train)：\n",
    "\n",
    "x_test 和 x_train 使用np.linspace(0, 1, num=...)生成线性分布的输入样本。\n",
    "提取标签 (y_test, y_train)：\n",
    "\n",
    "y_test 和 y_train 分别为测试和训练数据的真实标签。\n",
    "使用self.topology[0]提取出输出值。\n",
    "权重大小 (w_size)：\n",
    "\n",
    "权重大小w_size等于输入和输出神经元数量之和。对于一个简单的线性模型，权重数等于输入特征数，偏置也作为一个单独的参数。\n",
    "初始化采样存储：\n",
    "\n",
    "pos_w：用于存储所有采样的权重和偏置，形状为(samples, w_size)。\n",
    "pos_tau：用于存储噪声精度（逆方差），形状为(samples, 1)。\n",
    "fxtrain_samples 和 fxtest_samples：分别用于存储训练集和测试集上的预测结果，维度为(samples, trainsize)和(samples, testsize)。\n",
    "rmse_train 和 rmse_test：用于存储每次采样后计算的训练集和测试集的RMSE。\n",
    "2. 初始化权重和步长\n",
    "权重初始化 (w, w_proposal)：\n",
    "\n",
    "w和w_proposal是用于当前采样和提案的权重，使用标准正态分布初始化。\n",
    "步长设置 (step_w, step_eta)：\n",
    "\n",
    "step_w：控制权重的变化范围。\n",
    "step_eta：控制噪声精度参数的变化范围。\n",
    "3. 线性模型的初始化\n",
    "使用lin_model类初始化一个模型实例model。\n",
    "传入的参数包括训练数据、测试数据、特征数量和一个固定的学习率。\n",
    "注意：max_epoch设置为0，表示在sampler中并不涉及显式的训练过程，而是通过MCMC采样来优化权重。\n",
    "4. 计算初始预测和似然\n",
    "预测值计算 (pred_train, pred_test)：\n",
    "\n",
    "使用模型的evaluate_proposal()方法，传入当前权重w，计算训练集和测试集的预测值。\n",
    "计算噪声精度 (eta, tau_pro)：\n",
    "\n",
    "eta：计算训练集预测误差的方差的对数，以此得到噪声精度的一个度量。\n",
    "tau_pro：使用指数函数计算精度参数，即精度为方差的逆数。\n",
    "5. 计算初始先验似然和数据似然\n",
    "先验似然 (prior_likelihood)：\n",
    "\n",
    "使用self.prior_likelihood()方法计算当前权重的先验似然。\n",
    "参数包括sigma_squared、nu_1、nu_2等，用于表示先验分布的超参数。\n",
    "数据似然 (likelihood)：\n",
    "\n",
    "使用self.likelihood_func()方法计算训练集的似然值。\n",
    "返回似然值、训练集的预测值和RMSE。\n",
    "6. 打印初始状态并准备MCMC循环\n",
    "打印初始信息：打印初始权重的评估信息以及初始似然值，以便查看初始模型的性能。\n",
    "变量naccept：用于记录MCMC采样过程中被接受的提案数，初始化为0。\n",
    "代码的整体流程\n",
    "初始化采样参数和存储矩阵：\n",
    "包括存储权重和偏置、预测值以及每个采样的均方误差。\n",
    "初始化权重和噪声精度：\n",
    "初始化权重和用于提案的权重，以及步长参数。\n",
    "创建线性模型实例：\n",
    "使用训练数据和测试数据初始化模型。\n",
    "计算初始似然和先验：\n",
    "通过模型预测和计算方差，得到初始的似然和先验。\n",
    "'''\n",
    "def sampler(self):\n",
    "\n",
    "\t\t# ------------------- initialize MCMC\n",
    "\t\ttestsize = self.testdata.shape[0]\n",
    "\t\ttrainsize = self.traindata.shape[0]\n",
    "\t\tsamples = self.samples\n",
    "\n",
    "\t\tx_test = np.linspace(0, 1, num=testsize)\n",
    "\t\tx_train = np.linspace(0, 1, num=trainsize)\n",
    "\n",
    "\t\t#self.topology  # [input,   output]\n",
    "\t\ty_test = self.testdata[:, self.topology[0]]\n",
    "\t\ty_train = self.traindata[:, self.topology[0]]\n",
    "\t  \n",
    "\t\tw_size = self.topology[0]  + self.topology[1]  # num of weights and bias (eg. 4 + 1 in case of time series problems used)\n",
    "\n",
    "\t\tpos_w = np.ones((samples, w_size))  # posterior of all weights and bias over all samples\n",
    "\t\tpos_tau = np.ones((samples, 1))\n",
    "\n",
    "\t\tfxtrain_samples = np.ones((samples, trainsize))  # fx of train data over all samples\n",
    "\t\tfxtest_samples = np.ones((samples, testsize))  # fx of test data over all samples\n",
    "\t\trmse_train = np.zeros(samples)\n",
    "\t\trmse_test = np.zeros(samples)\n",
    "\n",
    "\t\tw = np.random.randn(w_size)\n",
    "\t\tw_proposal = np.random.randn(w_size)\n",
    "\n",
    "\t\tstep_w = 0.02;  # defines how much variation you need in changes to w\n",
    "\t\tstep_eta = 0.01;  \n",
    "\t\t# eta is an additional parameter to cater for noise in predictions (Gaussian likelihood). \n",
    "\t\t# note eta is used as tau in the sampler to consider log scale. \n",
    "\t\t# eta is not used in multinomial likelihood. \n",
    " \n",
    "\n",
    "\t\tmodel = lin_model(0 ,  self.traindata, self.testdata, self.topology[0], 0.1, self.regression) \n",
    "\n",
    "\t\tpred_train = model.evaluate_proposal(self.traindata, w)\n",
    "\t\tpred_test = model.evaluate_proposal(self.testdata, w)\n",
    "\n",
    "\t\teta = np.log(np.var(pred_train - y_train))\n",
    "\t\ttau_pro = np.exp(eta)\n",
    "\n",
    "\t\tprint('evaluate Initial w')\n",
    "\n",
    "\t\tsigma_squared = 5  # considered by looking at distribution of  similar trained  models - i.e distribution of weights and bias\n",
    "\t\tnu_1 = 0\n",
    "\t\tnu_2 = 0\n",
    "\n",
    "\t\tprior_likelihood = self.prior_likelihood(sigma_squared, nu_1, nu_2, w, tau_pro)  # takes care of the gradients\n",
    "\n",
    "\t\t[likelihood, pred_train, rmsetrain] = self.likelihood_func(model, self.traindata, w, tau_pro)\n",
    "\n",
    "\t\tprint(likelihood, ' initial likelihood')\n",
    "\t\t[likelihood_ignore, pred_test, rmsetest] = self.likelihood_func(model, self.testdata, w, tau_pro)\n",
    "\n",
    "\n",
    "\t\tnaccept = 0  "
   ],
   "id": "f83400658d50890a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''\n",
    "这段代码实现了一种基于马尔可夫链蒙特卡罗（MCMC）方法的采样算法，用于从后验分布中进行采样，目的是找到模型参数的最佳估计。这里使用的是一种Metropolis-Hastings（MH）采样算法。以下是代码的逐步解释：\n",
    "\n",
    "循环采样过程：\n",
    "\n",
    "使用 for i in range(samples - 1) 进行多次迭代来生成样本。\n",
    "在每次迭代中生成新的参数 w_proposal 和 eta_pro，这些新参数是通过在当前参数值的基础上加上随机噪声得到的。\n",
    "计算新的似然和先验：\n",
    "\n",
    "通过 self.likelihood_func 计算新的候选参数下的似然值 likelihood_proposal 以及训练和测试数据上的预测结果。\n",
    "计算候选参数的先验值 prior_prop，通过调用 self.prior_likelihood。\n",
    "Metropolis-Hastings准则：\n",
    "\n",
    "计算似然差值 diff_likelihood 和先验差值 diff_priorliklihood。\n",
    "使用这些差值来计算接受概率 mh_prob，并用一个随机数 u 来决定是否接受候选参数。\n",
    "如果 u < mh_prob，则接受候选参数并更新参数的值，否则保持现有参数。\n",
    "保存采样结果：\n",
    "\n",
    "将当前迭代得到的参数、预测值、均方误差（RMSE）等保存在相应的数组中，以便在后续分析中使用。\n",
    "计算接受率：\n",
    "\n",
    "计算采样的接受率 accept_ratio，即有多少次候选参数被接受。\n",
    "后处理：\n",
    "\n",
    "扔掉“燃烧期”（burn-in period）的样本，用于去除初始不稳定的采样。\n",
    "最后，计算并打印训练和测试集上的RMSE均值和标准差，来衡量模型的预测性能。\n",
    "总结来说，这段代码实现了一个基于Metropolis-Hastings算法的参数采样过程，用于优化某个模型的参数，并通过均方误差（RMSE）来评估模型的性能。主要步骤包括提议新参数、计算接受概率、根据接受概率更新参数，以及记录采样过程的结果。\n",
    "'''\n",
    "\n",
    "\n",
    "\t\tfor i in range(samples - 1):\n",
    "\n",
    "\t\t\tw_proposal = w + np.random.normal(0, step_w, w_size)\n",
    "\n",
    "\t\t\teta_pro = eta + np.random.normal(0, step_eta, 1)\n",
    "\t\t\ttau_pro = math.exp(eta_pro)\n",
    "\n",
    "\t\t\t[likelihood_proposal, pred_train, rmsetrain] = self.likelihood_func(model, self.traindata, w_proposal, tau_pro)\n",
    "\t\t\t[likelihood_ignore, pred_test, rmsetest] = self.likelihood_func(model, self.testdata, w_proposal, tau_pro)\n",
    "\n",
    "\t\t\t# likelihood_ignore  refers to parameter that will not be used in the alg.\n",
    "\n",
    "\t\t\tprior_prop = self.prior_likelihood(sigma_squared, nu_1, nu_2, w_proposal, tau_pro)  # takes care of the gradients\n",
    "\n",
    "\t\t\tdiff_likelihood = likelihood_proposal - likelihood # since we using log scale: based on https://www.rapidtables.com/math/algebra/Logarithm.html\n",
    "\t\t\tdiff_priorliklihood = prior_prop - prior_likelihood\n",
    "\n",
    "\t\t\tmh_prob = min(1, math.exp(diff_likelihood + diff_priorliklihood))\n",
    "\n",
    "\t\t\tu = random.uniform(0, 1)\n",
    "\n",
    "\t\t\tif u < mh_prob:\n",
    "\t\t\t\t# Update position\n",
    "\t\t\t\t#print    (i, ' is accepted sample')\n",
    "\t\t\t\tnaccept += 1\n",
    "\t\t\t\tlikelihood = likelihood_proposal\n",
    "\t\t\t\tprior_likelihood = prior_prop\n",
    "\t\t\t\tw = w_proposal\n",
    "\t\t\t\teta = eta_pro\n",
    "\t\t\t\trmse_train[i + 1,] = rmsetrain\n",
    "\t\t\t\trmse_test[i + 1,] = rmsetest\n",
    "\n",
    "\n",
    "\t\t\t\t#print (likelihood, prior_likelihood, rmsetrain, rmsetest, w, 'accepted')\n",
    "\n",
    "\t\t\t\tpos_w[i + 1,] = w_proposal\n",
    "\t\t\t\tpos_tau[i + 1,] = tau_pro\n",
    "\t\t\t\tfxtrain_samples[i + 1,] = pred_train\n",
    "\t\t\t\tfxtest_samples[i + 1,] = pred_test \n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\tpos_w[i + 1,] = pos_w[i,]\n",
    "\t\t\t\tpos_tau[i + 1,] = pos_tau[i,]\n",
    "\t\t\t\tfxtrain_samples[i + 1,] = fxtrain_samples[i,]\n",
    "\t\t\t\tfxtest_samples[i + 1,] = fxtest_samples[i,] \n",
    "\t\t\t\trmse_train[i + 1,] = rmse_train[i,]\n",
    "\t\t\t\trmse_test[i + 1,] = rmse_test[i,]\n",
    "\n",
    "\t\t \n",
    "\t\taccept_ratio = naccept / (samples * 1.0) * 100\n",
    "\n",
    "\n",
    "\t\tprint(accept_ratio, '% was accepted')\n",
    "\n",
    "\t\tburnin = 0.25 * samples  # use post burn in samples\n",
    "\n",
    "\t\tpos_w = pos_w[int(burnin):, ]\n",
    "\t\tpos_tau = pos_tau[int(burnin):, ] \n",
    "\t\trmse_train = rmse_train[int(burnin):]\n",
    "\t\trmse_test = rmse_test[int(burnin):] \n",
    "\n",
    "\n",
    "\t\trmse_tr = np.mean(rmse_train)\n",
    "\t\trmsetr_std = np.std(rmse_train)\n",
    "\t\trmse_tes = np.mean(rmse_test)\n",
    "\t\trmsetest_std = np.std(rmse_test)\n",
    "\t\tprint(rmse_tr, rmsetr_std, rmse_tes, rmsetest_std, ' rmse_tr, rmsetr_std, rmse_tes, rmsetest_std')"
   ],
   "id": "8c4c8c95e997dff5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''\n",
    "这段代码包含了两个函数，likelihood_func 和 prior_likelihood，用于计算贝叶斯神经网络中采样参数的似然和先验，帮助实现参数的贝叶斯优化。\n",
    "\n",
    "1. likelihood_func\n",
    "该函数计算神经网络在给定数据和权重下的似然值。具体步骤如下：\n",
    "\n",
    "参数：\n",
    "\n",
    "neuralnet：神经网络模型。\n",
    "data：输入数据。\n",
    "w：权重向量。\n",
    "tausq：噪声精度（逆方差）。\n",
    "实现：\n",
    "\n",
    "提取目标值：y = data[:, self.topology[0]]，从数据中提取目标值（真实输出）。\n",
    "计算模型预测：fx = neuralnet.evaluate_proposal(data, w)，使用给定的权重 w 来计算模型的预测值。\n",
    "计算均方根误差（RMSE）：rmse = self.rmse(fx, y)，计算预测值和目标值之间的RMSE。\n",
    "计算似然：loss = -0.5 * np.log(2 * math.pi * tausq) - 0.5 * np.square(y - fx) / tausq，这一步计算对数似然，假设误差服从高斯分布。\n",
    "返回值：return [np.sum(loss), fx, rmse]，返回对数似然的和、模型预测值和RMSE。\n",
    "2. prior_likelihood\n",
    "该函数用于计算给定权重和噪声精度下的先验对数概率，用于评估参数在先验分布下的合理性。\n",
    "参数：\n",
    "\n",
    "sigma_squared：权重的先验方差。\n",
    "nu_1 和 nu_2：控制精度的先验参数。\n",
    "w：权重向量。\n",
    "tausq：噪声精度。\n",
    "实现：\n",
    "\n",
    "提取神经网络结构信息：\n",
    "h = self.topology[1]：隐藏神经元的数量。\n",
    "d = self.topology[0]：输入神经元的数量。\n",
    "计算先验的第一部分：part1 = -1 * ((d * h + h + 2) / 2) * np.log(sigma_squared)，先验概率的第一部分涉及对数方差，反映了权重的复杂度。\n",
    "计算先验的第二部分：part2 = 1 / (2 * sigma_squared) * (sum(np.square(w)))，这是权重的平方和项，代表L2正则化。\n",
    "计算总的对数先验：log_loss = part1 - part2 - (1 + nu_1) * np.log(tausq) - (nu_2 / tausq)，包含了权重的对数先验和精度参数的对数先验。\n",
    "返回值：return log_loss，返回先验对数概率。\n",
    "总结\n",
    "likelihood_func 用于计算在给定数据和权重下模型的对数似然，反映了模型在给定权重下对数据的拟合程度。\n",
    "prior_likelihood 用于计算权重和噪声精度的先验对数概率，反映了参数符合先验分布的程度。\n",
    "'''\n",
    "# https://github.com/sydney-machine-learning/Bayesianneuralnetworks-MCMC-tutorial/blob/main/code/BNN_reg_cls.py   \n",
    "    \n",
    "    def likelihood_func(self, neuralnet, data, w, tausq):\n",
    "\t\ty = data[:, self.topology[0]]\n",
    "\t\tfx = neuralnet.evaluate_proposal(data, w)\n",
    "\t\trmse = self.rmse(fx, y)\n",
    "\t\tloss = -0.5 * np.log(2 * math.pi * tausq) - 0.5 * np.square(y - fx) / tausq\n",
    "\t\treturn [np.sum(loss), fx, rmse]\n",
    "\n",
    "\tdef prior_likelihood(self, sigma_squared, nu_1, nu_2, w, tausq):\n",
    "\t\th = self.topology[1]  # number hidden neurons\n",
    "\t\td = self.topology[0]  # number input neurons\n",
    "\t\tpart1 = -1 * ((d * h + h + 2) / 2) * np.log(sigma_squared)\n",
    "\t\tpart2 = 1 / (2 * sigma_squared) * (sum(np.square(w)))\n",
    "\t\tlog_loss = part1 - part2  - (1 + nu_1) * np.log(tausq) - (nu_2 / tausq)\n",
    "\t\treturn log_loss"
   ],
   "id": "8c0ce420c3cd3756",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''\n",
    "1. decode(self, w)\n",
    "这个函数用于将给定的一维权重向量 w 解码成神经网络的权重矩阵和偏置向量。\n",
    "\n",
    "参数：\n",
    "\n",
    "w：包含所有权重和偏置的一维向量。\n",
    "实现：\n",
    "\n",
    "计算隐藏层的权重大小 w_layer1size 和输出层的权重大小 w_layer2size。\n",
    "第一层权重：w_layer1 是第一个隐藏层的权重部分，通过 np.reshape 将其重塑为 W1 矩阵。\n",
    "第二层权重：w_layer2 是输出层的权重部分，通过 np.reshape 将其重塑为 W2 矩阵。\n",
    "偏置向量：\n",
    "self.B1 是隐藏层的偏置。\n",
    "self.B2 是输出层的偏置。\n",
    "这个函数用于解码整个权重向量，使神经网络可以进行前向传播和后向传播。\n",
    "\n",
    "2. langevin_gradient(self, data, w, depth)\n",
    "这个函数实现了使用随机梯度下降（SGD）进行后向传播，以计算Langevin梯度，用于更新权重。\n",
    "\n",
    "参数：\n",
    "\n",
    "data：输入数据集。\n",
    "w：权重向量。\n",
    "depth：训练的深度，即多少次迭代。\n",
    "实现：\n",
    "\n",
    "使用 decode(w) 解码给定的权重向量。\n",
    "初始化输入和输出：Input 和 Desired 用于存储每个样本的输入和期望输出。\n",
    "进行多次迭代（由 depth 决定），每次迭代中：\n",
    "遍历数据集，使用 ForwardPass 进行前向传播，计算输出。\n",
    "使用 BackwardPass 进行后向传播，以更新权重。\n",
    "调用 self.encode() 来重新编码更新后的权重为一维向量。\n",
    "返回更新后的权重 w_updated。\n",
    "这个函数的目的是通过Langevin梯度来更新模型参数，从而提高模型性能。\n",
    "\n",
    "3. evaluate_proposal(self, data, w)\n",
    "该函数用于给定数据和权重，评估模型的预测结果。\n",
    "\n",
    "参数：\n",
    "\n",
    "data：输入数据。\n",
    "w：权重向量。\n",
    "实现：\n",
    "\n",
    "使用 decode(w) 来解码给定的权重向量。\n",
    "初始化输入和输出：Input 用于存储输入样本，fx 用于存储模型的预测输出。\n",
    "进行前向传播：\n",
    "遍历数据集中的所有样本。\n",
    "使用 ForwardPass 对每个样本进行前向传播，得到输出 self.out。\n",
    "将输出存储在 fx 中。\n",
    "返回预测结果 fx。\n",
    "这个函数的主要目的是使用给定权重对数据集进行预测，以便评估模型在当前权重下的表现。\n",
    "\n",
    "总结\n",
    "decode：将一维的权重向量解码为神经网络各层的权重矩阵和偏置向量，使其可以用于计算。\n",
    "langevin_gradient：使用SGD进行后向传播，通过Langevin梯度来更新权重，提高模型性能。\n",
    "evaluate_proposal：给定数据和权重，使用神经网络对输入数据进行前向传播，并返回预测结果。\n",
    "'''\n",
    "# https://github.com/sydney-machine-learning/Bayesianneuralnetworks-MCMC-tutorial/blob/main/code/BNN_reg_cls.py   \n",
    "    def decode(self, w):\n",
    "\t\tw_layer1size = self.Top[0] * self.Top[1]\n",
    "\t\tw_layer2size = self.Top[1] * self.Top[2]\n",
    "\n",
    "\t\tw_layer1 = w[0:w_layer1size]\n",
    "\t\tself.W1 = np.reshape(w_layer1, (self.Top[0], self.Top[1]))\n",
    "\n",
    "\t\tw_layer2 = w[w_layer1size:w_layer1size + w_layer2size]\n",
    "\t\tself.W2 = np.reshape(w_layer2, (self.Top[1], self.Top[2]))\n",
    "\t\tself.B1 = w[w_layer1size + w_layer2size:w_layer1size + w_layer2size + self.Top[1]]\n",
    "\t\tself.B2 = w[w_layer1size + w_layer2size + self.Top[1]:w_layer1size + w_layer2size + self.Top[1] + self.Top[2]]\n",
    "\n",
    "\tdef langevin_gradient(self, data, w, depth):  # BP with SGD (Stocastic BP)\n",
    "\n",
    "\t\tself.decode(w)  # method to decode w into W1, W2, B1, B2.\n",
    "\t\tsize = data.shape[0]\n",
    "\n",
    "\t\tInput = np.zeros((1, self.Top[0]))  # temp hold input\n",
    "\t\tDesired = np.zeros((1, self.Top[2]))\n",
    "\t\tfx = np.zeros(size)\n",
    "\n",
    "\t\tfor i in xrange(0, depth):\n",
    "\t\t\tfor i in xrange(0, size):\n",
    "\t\t\t\tpat = i\n",
    "\t\t\t\tInput = data[pat, 0:self.Top[0]]\n",
    "\t\t\t\tDesired = data[pat, self.Top[0]:]\n",
    "\t\t\t\tself.ForwardPass(Input)\n",
    "\t\t\t\tself.BackwardPass(Input, Desired)\n",
    "\n",
    "\t\tw_updated = self.encode()\n",
    "\n",
    "\t\treturn  w_updated\n",
    "\n",
    "\tdef evaluate_proposal(self, data, w ):  # BP with SGD (Stocastic BP)\n",
    "\n",
    "\t\tself.decode(w)  # method to decode w into W1, W2, B1, B2.\n",
    "\t\tsize = data.shape[0]\n",
    "\n",
    "\t\tInput = np.zeros((1, self.Top[0]))  # temp hold input\n",
    "\t\tDesired = np.zeros((1, self.Top[2]))\n",
    "\t\tfx = np.zeros(size)\n",
    "\n",
    "\t\tfor i in xrange(0, size):  # to see what fx is produced by your current weight update\n",
    "\t\t\tInput = data[i, 0:self.Top[0]]\n",
    "\t\t\tself.ForwardPass(Input)\n",
    "\t\t\tfx[i] = self.out\n",
    "\n",
    "\t\treturn fx\n"
   ],
   "id": "9ba001b5b55eb1d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''\n",
    "这段代码实现了基于Metropolis-Hastings (MH) 算法的参数采样过程，其中结合了Langevin梯度，用于改进采样效率。这种方法用于贝叶斯神经网络中的马尔可夫链蒙特卡罗 (MCMC) 采样，以探索参数空间。以下是代码的详细解释：\n",
    "\n",
    "1. Langevin 梯度的使用\n",
    "在这个采样过程中，有时会使用Langevin梯度来改进采样效率。Langevin梯度结合了梯度信息以更好地指导参数更新，而不只是纯粹的随机步进。\n",
    "\n",
    "lx = np.random.uniform(0,1,1)：\n",
    "\n",
    "生成一个在0到1之间的随机数，用于决定当前迭代是否使用Langevin梯度。\n",
    "if (self.use_langevin_gradients is True) and (lx < self.l_prob)：\n",
    "\n",
    "如果设置了使用Langevin梯度（self.use_langevin_gradients为True），并且生成的随机数 lx 小于 self.l_prob，则进行Langevin梯度步骤。\n",
    "w_gd = neuralnet.langevin_gradient(self.traindata, w.copy(), self.sgd_depth)：\n",
    "\n",
    "使用Langevin梯度 (langevin_gradient) 更新权重 w，得到梯度更新后的权重 w_gd。\n",
    "w_proposal = np.random.normal(w_gd, step_w, w_size)：\n",
    "\n",
    "使用更新后的权重 w_gd 为均值，进行一个随机扰动，生成候选权重 w_proposal。\n",
    "计算反向提议概率差值：\n",
    "\n",
    "w_prop_gd = neuralnet.langevin_gradient(self.traindata, w_proposal.copy(), self.sgd_depth)：\n",
    "使用 w_proposal 再次计算Langevin梯度。\n",
    "wc_delta = (w - w_prop_gd) 和 wp_delta = (w_proposal - w_gd)：\n",
    "计算从候选权重和当前权重之间的差异向量。\n",
    "first 和 second：\n",
    "first 代表从 w_prop_gd 到 w 的提议概率的负对数值，second 代表从 w_gd 到 w_proposal 的提议概率的负对数值。\n",
    "使用这些差值来计算两个提议方向之间的概率差异（diff_prop），这在Langevin方法中是必要的，以确保MH步骤中的对称性。\n",
    "diff_prop = first - second：\n",
    "\n",
    "计算提议概率的对数差异。\n",
    "2. 不使用Langevin梯度时的采样\n",
    "如果当前不使用Langevin梯度，则 diff_prop = 0，并通过随机扰动直接生成候选权重 w_proposal。\n",
    "3. 更新噪声参数 eta\n",
    "eta_pro = eta + np.random.normal(0, step_eta, 1)：\n",
    "更新噪声参数 eta，通过在当前值基础上加一个随机扰动生成新的 eta_pro。\n",
    "tau_pro = math.exp(eta_pro)：\n",
    "计算噪声精度 tau_pro，是 eta_pro 的指数形式。\n",
    "4. 计算似然、先验和MH概率\n",
    "似然计算：\n",
    "\n",
    "[likelihood_proposal, pred_train, rmsetrain] = self.likelihood_func(...)：计算候选参数下的似然值。\n",
    "[likelihood_ignore, pred_test, rmsetest] = self.likelihood_func(...)：计算候选参数下在测试集上的似然值（忽略对MH步骤的影响）。\n",
    "先验计算：\n",
    "\n",
    "prior_prop = self.prior_likelihood(...)：计算候选参数下的先验对数概率。\n",
    "计算差值：\n",
    "\n",
    "diff_prior = prior_prop - prior_current：计算先验的差值。\n",
    "diff_likelihood = likelihood_proposal - likelihood：计算似然的差值。\n",
    "5. 计算Metropolis-Hastings (MH) 概率\n",
    "mh_prob = min(1, math.exp(diff_likelihood + diff_prior + diff_prop))：\n",
    "\n",
    "计算MH概率，结合似然、先验和提议概率的差值。\n",
    "异常处理：\n",
    "\n",
    "由于 diff_likelihood + diff_prior + diff_prop 有可能非常大，导致 math.exp() 产生溢出错误，这里使用 try...except 来捕获 OverflowError，并在发生溢出时将 mh_prob 设为1，保证采样过程继续。\n",
    "'''\n",
    "#Source: https://github.com/sydney-machine-learning/Bayesianneuralnetworks-MCMC-tutorial/blob/main/code/BNN_reg_cls.py\n",
    "for i in range(samples - 1):\n",
    "\n",
    "    lx = np.random.uniform(0,1,1)\n",
    "\n",
    "    if (self.use_langevin_gradients is True) and (lx< self.l_prob):  \n",
    "        w_gd = neuralnet.langevin_gradient(self.traindata, w.copy(), self.sgd_depth) # Eq 8\n",
    "        w_proposal = np.random.normal(w_gd, step_w, w_size) # Eq 7\n",
    "        w_prop_gd = neuralnet.langevin_gradient(self.traindata, w_proposal.copy(), self.sgd_depth) \n",
    "        #first = np.log(multivariate_normal.pdf(w , w_prop_gd , sigma_diagmat)) #how likely is that you end up with w given w_prop_gd\n",
    "        #second = np.log(multivariate_normal.pdf(w_proposal , w_gd , sigma_diagmat)) # this gives numerical instability - hence we give a simple implementation next that takes out log \n",
    "\n",
    "        wc_delta = (w- w_prop_gd) \n",
    "        wp_delta = (w_proposal - w_gd )\n",
    "        sigma_sq = step_w\n",
    "\n",
    "        first = -0.5 * np.sum(wc_delta  *  wc_delta  ) / sigma_sq  # this is wc_delta.T  *  wc_delta /sigma_sq\n",
    "        second = -0.5 * np.sum(wp_delta * wp_delta ) / sigma_sq\n",
    "\n",
    "        #in random-walk idealy first - second would be 0 or close to 0.\n",
    "        diff_prop =  first - second  \n",
    "        langevin_count = langevin_count + 1\n",
    "    else:\n",
    "        diff_prop = 0\n",
    "        w_proposal = np.random.normal(w, step_w, w_size)\n",
    "\n",
    "    eta_pro = eta + np.random.normal(0, step_eta, 1)\n",
    "    tau_pro = math.exp(eta_pro)\n",
    "\n",
    "    [likelihood_proposal, pred_train, rmsetrain] = self.likelihood_func(neuralnet, self.traindata, w_proposal,\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttau_pro)\n",
    "    [likelihood_ignore, pred_test, rmsetest] = self.likelihood_func(neuralnet, self.testdata, w_proposal,\n",
    "                                                                    tau_pro) \n",
    "\n",
    "    prior_prop = self.prior_likelihood(sigma_squared, nu_1, nu_2, w_proposal,\n",
    "                                        tau_pro)  # takes care of the gradients\n",
    "\n",
    "\n",
    "    diff_prior = prior_prop - prior_current\n",
    "\n",
    "    diff_likelihood = likelihood_proposal - likelihood\n",
    "\n",
    "    #mh_prob = min(1, math.exp(diff_likelihood + diff_prior + diff_prop))\n",
    "\n",
    "    try:\n",
    "        mh_prob = min(1, math.exp(diff_likelihood+diff_prior+ diff_prop))\n",
    "\n",
    "    except OverflowError as e:\n",
    "        mh_prob = 1\n",
    "\n"
   ],
   "id": "ef68b2b057aefdda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    " '''\n",
    " 这段代码实现了基于马尔可夫链蒙特卡洛(MCMC)方法中的Metropolis-Hastings采样，用于优化神经网络的参数。\n",
    "\n",
    "代码首先检查是否要使用Langevin梯度（self.use_langevin_gradients），如果满足条件，则使用Langevin梯度更新参数。\n",
    "\n",
    "w_gd = neuralnet.langevin_gradient(self.traindata, w.copy(), self.sgd_depth)：调用神经网络的langevin_gradient方法计算Langevin梯度。\n",
    "w_proposal = np.random.normal(w_gd, step_w, w_size)：生成一个新的参数w_proposal，基于Langevin梯度（类似于随机游走，但带有梯度方向）。\n",
    "代码计算Langevin梯度的对称性校正项diff_prop。\n",
    "\n",
    "w_prop_gd表示w_proposal经过Langevin梯度后的值。\n",
    "wc_delta和wp_delta分别是当前参数w与w_prop_gd的差异以及提议参数w_proposal与w_gd的差异。\n",
    "使用这些差异计算概率对称性校正项first和second，并最终得到diff_prop。\n",
    "代码最后一步是计算Metropolis-Hastings的接受概率mh_prob。\n",
    "\n",
    "diff_prior表示提议分布与当前分布的先验差异。\n",
    "diff_likelihood表示提议分布与当前分布的似然差异。\n",
    "mh_prob是一个在0和1之间的概率，用于决定是否接受新的参数。这个概率由diff_likelihood、diff_prior以及对称性校正项diff_prop一起计算出来。\n",
    " '''\n",
    " if (self.use_langevin_gradients is True) and (lx< self.l_prob):  \n",
    "        w_gd = neuralnet.langevin_gradient(self.traindata, w.copy(), self.sgd_depth) # Eq 8\n",
    "        w_proposal = np.random.normal(w_gd, step_w, w_size) # Eq 7\n",
    "        w_prop_gd = neuralnet.langevin_gradient(self.traindata, w_proposal.copy(), self.sgd_depth) \n",
    "        #first = np.log(multivariate_normal.pdf(w , w_prop_gd , sigma_diagmat))\n",
    "        #(how likely is that you end up with w given w_prop_gd)\n",
    "        #second = np.log(multivariate_normal.pdf(w_proposal , w_gd , sigma_diagmat)) \n",
    "        #(this gives numerical instability - hence we give a simple implementation next that takes out log)\n",
    "\n",
    "        wc_delta = (w- w_prop_gd) \n",
    "        wp_delta = (w_proposal - w_gd )\n",
    "        sigma_sq = step_w\n",
    "\n",
    "        first = -0.5 * np.sum(wc_delta  *  wc_delta  ) / sigma_sq  \n",
    "        second = -0.5 * np.sum(wp_delta * wp_delta ) / sigma_sq\n",
    "\n",
    "        #in random-walk idealy first - second would be 0 or close to 0 \n",
    "        #and hence we assume it cancels out\n",
    "        diff_prop =  first - second  \n",
    "\n",
    "\n",
    "# get likelihood and prior likelihood values (prior_prop and diff_likelihood)\n",
    "\n",
    "    diff_prior = prior_prop - prior_current\n",
    "    diff_likelihood = likelihood_proposal - likelihood\n",
    "    mh_prob = min(1, math.exp(diff_likelihood + diff_prior + diff_prop))\n"
   ],
   "id": "bfa6141a9f60f374",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''\n",
    "1. loglikelihood(self, neuralnet, data, w, tausq)\n",
    "这个函数计算神经网络的对数似然值，具体取决于问题类型是回归（regression）还是分类（classification）。\n",
    "\n",
    "对于回归问题，调用gaussian_loglikelihood函数。\n",
    "对于分类问题，调用multinomial_loglikelihood函数。\n",
    "返回值是包含对数似然值、预测值以及性能指标（例如均方根误差或准确率）。\n",
    "2. prior(self, sigma_squared, nu_1, nu_2, w, tausq)\n",
    "这个函数用于计算先验分布的对数值。\n",
    "\n",
    "如果是回归问题，调用prior_regression计算先验。\n",
    "如果是分类问题，调用prior_classification计算先验。\n",
    "返回先验的对数值。\n",
    "3. gaussian_loglikelihood(self, neuralnet, data, w, tausq)\n",
    "这个函数计算回归问题的对数似然值，假设误差服从高斯分布。\n",
    "\n",
    "y是数据中的目标值。\n",
    "fx, prob = neuralnet.evaluate_proposal(data, w)：计算神经网络在当前参数w下的输出预测fx，prob被忽略。\n",
    "rmse = self.rmse(fx, y)：计算预测fx和目标值y之间的均方根误差。\n",
    "对数似然值log_lhood是根据高斯分布公式计算的，使用y和fx的误差以及噪声参数tausq。\n",
    "返回对数似然值、预测值和均方根误差。\n",
    "4. prior_regression(self, sigma_squared, nu_1, nu_2, w, tausq)\n",
    "这个函数计算回归问题中参数的先验对数概率。\n",
    "\n",
    "先验分布假设权重和偏置是正态分布。\n",
    "h和d分别表示隐藏层神经元和输入层神经元的数量。\n",
    "part1和part2用于计算基于正态分布的先验对数概率，tausq部分也包含在先验中。\n",
    "返回先验的对数损失log_loss。\n",
    "5. multinomial_loglikelihood(self, neuralnet, data, w)\n",
    "这个函数计算分类问题的对数似然值。\n",
    "\n",
    "y是数据中的目标类别。\n",
    "fx, prob = neuralnet.evaluate_proposal(data,w)：计算神经网络在当前参数w下的输出预测fx和对应的概率prob。\n",
    "acc = self.accuracy(fx, y)：计算预测的准确率。\n",
    "使用多项分布的对数似然公式，计算每个样本的对数似然值lhood，其中z[i, j]是用于标记类别的指示符。\n",
    "返回对数似然值、预测值和准确率。\n",
    "6. prior_classification(self, sigma_squared, nu_1, nu_2, w)\n",
    "这个函数计算分类问题中参数的先验对数概率。\n",
    "\n",
    "类似于prior_regression，但计算方式中会根据分类输出的结构有所不同。\n",
    "先验同样假设权重服从正态分布。\n",
    "log_loss是先验对数损失。\n",
    "总结\n",
    "loglikelihood和prior函数分别计算了不同类型问题的对数似然值和先验对数概率。\n",
    "gaussian_loglikelihood和multinomial_loglikelihood分别用于回归和分类问题的似然值计算。\n",
    "prior_regression和prior_classification用于回归和分类问题中先验对数概率的计算。\n",
    "'''\n",
    "#taken from: https://github.com/sydney-machine-learning/Bayesianneuralnetworks-MCMC-tutorial/blob/main/code/BNN_reg_cls.py\n",
    "\n",
    "\tdef loglikelihood(self, neuralnet, data, w, tausq): \n",
    "\n",
    "\t\tif self.prob == 'regression':\n",
    "\t\t\t[log_lhood, prediction, perf] = self.gaussian_loglikelihood(neuralnet, data, w, tausq)\n",
    "\t\telif self.prob == 'classification':\n",
    "\t\t\t[log_lhood, prediction, perf] = self.multinomial_loglikelihood(neuralnet, data, w)\n",
    "\n",
    "\t\treturn [log_lhood, prediction, perf]\n",
    "\n",
    "\tdef prior(self, sigma_squared, nu_1, nu_2, w, tausq): \n",
    "\n",
    "\t\tif self.prob == 'regression':\n",
    "\t\t\tlogprior = self.prior_regression(sigma_squared, nu_1, nu_2, w, tausq)\n",
    "\t\telif self.prob == 'classification':\n",
    "\t\t\tlogprior = self.prior_classification(sigma_squared, nu_1, nu_2, w)\n",
    "\n",
    "\t\treturn logprior\n",
    "\n",
    "\tdef gaussian_loglikelihood(self, neuralnet, data, w, tausq): \n",
    "\n",
    "\t\ty = data[:, self.topology[0]]\n",
    "\t\tfx, prob = neuralnet.evaluate_proposal(data, w) #ignore prob\n",
    "\t\trmse = self.rmse(fx, y) \n",
    "\n",
    "\t\tn = y.shape[0]  # will change for multiple outputs (y.shape[0]*y.shape[1])\n",
    "\t\tlog_lhood = -n/2 * np.log(2 * math.pi * tausq) - (1/(2*tausq)) * np.sum(np.square(y - fx))\n",
    "\t\treturn [log_lhood, fx, rmse]\n",
    "\n",
    "\tdef prior_regression(self, sigma_squared, nu_1, nu_2, w, tausq): # for weights and biases and tausq\n",
    "\t\th = self.topology[1]  # number hidden neurons\n",
    "\t\td = self.topology[0]  # number input neurons\n",
    "\t\tpart1 = -1 * ((d * h + h + 2) / 2) * np.log(sigma_squared)\n",
    "\t\tpart2 = 1 / (2 * sigma_squared) * (sum(np.square(w)))\n",
    "\t\tlog_loss = part1 - part2  - (1 + nu_1) * np.log(tausq) - (nu_2 / tausq)\n",
    "\t\treturn log_loss\n",
    "\n",
    "\n",
    "\tdef multinomial_loglikelihood(self, neuralnet, data, w):\n",
    "\t\ty = data[:, self.topology[0]]\n",
    "\t\tfx, prob = neuralnet.evaluate_proposal(data,w)\n",
    "\t\tacc= self.accuracy(fx,y)\n",
    "\t\tz = np.zeros((data.shape[0],self.topology[2]))\n",
    "\t\tlhood = 0\n",
    "\t\tfor i in range(data.shape[0]):\n",
    "\t\t\tfor j in range(self.topology[2]):\n",
    "\t\t\t\tif j == y[i]:\n",
    "\t\t\t\t\tz[i,j] = 1\n",
    "\t\t\t\tlhood += z[i,j]*np.log(prob[i,j])\n",
    "\n",
    "\t\treturn [lhood, fx, acc]\n",
    "\n",
    "\tdef prior_classification(self, sigma_squared, nu_1, nu_2, w): # for weights and biases only\n",
    "\t\th = self.topology[1]  # number hidden neurons\n",
    "\t\td = self.topology[0]  # number input neurons\n",
    "\t\tpart1 = -1 * ((d * h + h + self.topology[2]+h*self.topology[2]) / 2) * np.log(sigma_squared)\n",
    "\t\tpart2 = 1 / (2 * sigma_squared) * (sum(np.square(w)))\n",
    "\t\tlog_loss = part1 - part2\n",
    "\t\treturn log_loss\n"
   ],
   "id": "88cea67eab14e831",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''\n",
    "这段代码实现了贝叶斯神经网络中使用Metropolis-Hastings算法进行参数采样的过程，并使用Langevin梯度来提高采样效率。让我们逐步分解代码并理解其逻辑：\n",
    "\n",
    "代码逐步解释\n",
    "循环采样（for i in range(samples - 1)）：\n",
    "\n",
    "代码在一个循环中执行多个采样步骤，循环次数为samples - 1。\n",
    "随机变量lx用于控制是否使用Langevin梯度：\n",
    "\n",
    "lx = np.random.uniform(0, 1, 1)生成一个0到1之间的随机数。\n",
    "如果使用Langevin梯度（self.use_langevin_gradients is True）且lx小于self.l_prob，则应用Langevin动态来更新参数。\n",
    "应用Langevin梯度更新参数：\n",
    "\n",
    "w_gd = neuralnet.langevin_gradient(self.traindata, w.copy(), self.sgd_depth)：计算当前权重w在训练数据下的Langevin梯度。\n",
    "w_proposal = np.random.normal(w_gd, step_w, w_size)：生成新的权重提议w_proposal，这是基于Langevin梯度的高斯分布。\n",
    "w_prop_gd = neuralnet.langevin_gradient(self.traindata, w_proposal.copy(), self.sgd_depth)：计算提议权重的Langevin梯度。\n",
    "diff_prop是一个对称性校正项，通过计算w和w_proposal在梯度方向上的差异来得到。\n",
    "如果不使用Langevin梯度，diff_prop设置为0，且直接使用当前权重生成一个高斯分布的权重提议w_proposal。\n",
    "计算似然和先验：\n",
    "\n",
    "如果是回归问题，更新噪声参数eta_pro并计算相应的精度tau_pro。\n",
    "self.loglikelihood(neuralnet, self.traindata, w_proposal, tau_pro)：计算提议权重在训练数据上的对数似然值。\n",
    "self.loglikelihood(neuralnet, self.testdata, w_proposal, tau_pro)：计算提议权重在测试数据上的对数似然值（用于评估，不用于采样）。\n",
    "self.prior(sigma_squared, nu_1, nu_2, w_proposal, tau_pro)：计算提议权重的先验概率。\n",
    "计算差异项：\n",
    "\n",
    "diff_prior = prior_prop - prior_current：计算先验的差异。\n",
    "diff_likelihood = likelihood_proposal - likelihood：计算似然的差异。\n",
    "Metropolis-Hastings接受概率：\n",
    "\n",
    "mh_prob = min(1, math.exp(diff_likelihood + diff_prior + diff_prop))：计算Metropolis-Hastings接受概率。\n",
    "如果对数值的和太大导致溢出，捕获OverflowError并设置接受概率为1，表示总是接受提议。\n",
    "接受或拒绝提议：\n",
    "\n",
    "生成随机数u = random.uniform(0, 1)。\n",
    "如果u < mh_prob，接受提议权重：\n",
    "更新当前的似然、先验、权重以及噪声参数（对于回归）。\n",
    "naccept计数增加，用于跟踪接受的提议数目。\n",
    "'''\n",
    "\n",
    "\t\tfor i in range(samples - 1):\n",
    "\n",
    "\t\t\tlx = np.random.uniform(0,1,1)\n",
    "\n",
    "\t\t\tif (self.use_langevin_gradients is True) and (lx< self.l_prob):  \n",
    "\t\t\t\tw_gd = neuralnet.langevin_gradient(self.traindata, w.copy(), self.sgd_depth)  \n",
    "\t\t\t\tw_proposal = np.random.normal(w_gd, step_w, w_size)  \n",
    "\t\t\t\tw_prop_gd = neuralnet.langevin_gradient(self.traindata, w_proposal.copy(), self.sgd_depth) \n",
    "\t\t\t\t#first = np.log(multivariate_normal.pdf(w , w_prop_gd , sigma_diagmat)) \n",
    "\t\t\t\t#second = np.log(multivariate_normal.pdf(w_proposal , w_gd , sigma_diagmat)) \n",
    "\t\t\t\t# this gives numerical instability - hence we give a simple implementation next that takes out log \n",
    "\n",
    "\t\t\t\twc_delta = (w- w_prop_gd) \n",
    "\t\t\t\twp_delta = (w_proposal - w_gd )\n",
    "\n",
    "\t\t\t\tsigma_sq = step_w\n",
    "\n",
    "\t\t\t\tfirst = -0.5 * np.sum(wc_delta  *  wc_delta  ) / sigma_sq  # this is wc_delta.T  *  wc_delta /sigma_sq\n",
    "\t\t\t\tsecond = -0.5 * np.sum(wp_delta * wp_delta ) / sigma_sq\n",
    "\n",
    "\t\t\t\tdiff_prop =  first - second  \n",
    "\t\t\t\tlangevin_count = langevin_count + 1\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\tdiff_prop = 0\n",
    "\t\t\t\tw_proposal = np.random.normal(w, step_w, w_size)\n",
    "\n",
    "\n",
    "\t\t\tif self.prob == 'regression': \n",
    "\t\t\t\teta_pro = eta + np.random.normal(0, step_eta, 1)\n",
    "\t\t\t\ttau_pro = math.exp(eta_pro)\n",
    "\t\t\telse:# not used in case of classification\n",
    "\t\t\t\teta_pro = 0\n",
    "\t\t\t\ttau_pro = 0\n",
    "\n",
    "\n",
    "\t\t\t[likelihood_proposal, pred_train, p_train] = self.loglikelihood(neuralnet, self.traindata, w_proposal,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttau_pro)\n",
    "\t\t\t[likelihood_ignore, pred_test, p_test] = self.loglikelihood(neuralnet, self.testdata, w_proposal,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttau_pro) \n",
    "\n",
    "\t\t\tprior_prop = self.prior(sigma_squared, nu_1, nu_2, w_proposal,\n",
    "\t\t\t\t\t\t\t\t\t\t\t   tau_pro)  # takes care of the gradients\n",
    "\n",
    "\n",
    "\t\t\tdiff_prior = prior_prop - prior_current\n",
    "\n",
    "\t\t\tdiff_likelihood = likelihood_proposal - likelihood\n",
    "\n",
    "\t\t\t#mh_prob = min(1, math.exp(diff_likelihood + diff_prior + diff_prop))\n",
    "\n",
    "\t\t\ttry:\n",
    "\t\t\t\tmh_prob = min(1, math.exp(diff_likelihood+diff_prior+ diff_prop))\n",
    "\n",
    "\t\t\texcept OverflowError as e:\n",
    "\t\t\t\tmh_prob = 1\n",
    "\n",
    "\n",
    "\t\t\tu = random.uniform(0, 1)\n",
    "\n",
    "\t\t\tif u < mh_prob:\n",
    "\t\t\t\t# Update position \n",
    "\t\t\t\tnaccept += 1\n",
    "\t\t\t\tlikelihood = likelihood_proposal\n",
    "\t\t\t\tprior_current = prior_prop\n",
    "\t\t\t\tw = w_proposal\n",
    "\t\t\t\teta = eta_pro #only used for regression"
   ],
   "id": "6b5014941fe3b83c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''\n",
    "这段代码使用了Python的NumPy、SciPy、Pandas、Matplotlib和Seaborn库来生成和可视化统计数据。具体步骤如下：\n",
    "\n",
    "1. 导入必要的库\n",
    "导入了常用的科学计算和数据可视化库，如NumPy、SciPy、Pandas、Matplotlib和Seaborn。\n",
    "设置了Seaborn的样式为white，上下文为talk（适合展示）。\n",
    "2. 生成随机数据\n",
    "使用np.random.seed(123)来设置随机种子，使得结果可以复现。\n",
    "使用data = np.random.randn(200)生成200个服从标准正态分布的随机数据。\n",
    "3. 使用Seaborn绘制直方图\n",
    "使用sns.distplot()绘制直方图，并且通过设置kde=True来添加核密度估计（KDE）曲线。\n",
    "核密度估计是一种平滑数据分布的方式。\n",
    "使用plt.savefig('histo_seaborn.png')保存图像为histo_seaborn.png。\n",
    "使用plt.clf()清除当前图像，便于后续绘图。\n",
    "4. 使用Matplotlib绘制直方图\n",
    "使用plt.hist()绘制直方图，参数bins='auto'根据数据自动选择适合的分箱数。\n",
    "设置颜色为#0504aa，不透明度为alpha=0.7，rwidth=0.85表示直方条的相对宽度。\n",
    "添加网格和标签后，保存图像为histo_matplotlib.png，并使用plt.clf()清除当前图像。\n",
    "5. 计算后验分布（使用贝叶斯更新）\n",
    "定义了函数calc_posterior_analytical(data, x, mu_0, sigma_0)来计算后验分布。\n",
    "假设观测数据data服从已知标准差的正态分布，使用贝叶斯定理来更新先验分布。\n",
    "先验均值为mu_0，标准差为sigma_0。\n",
    "计算后验均值mu_post和后验标准差sigma_post，返回相应的概率密度值。\n",
    "使用calc_posterior_analytical(data, x, 0., 1.)计算在x范围内的后验概率密度，其中x = np.linspace(-1, 1, 50)为区间[-1, 1]上的50个点。\n",
    "打印出计算的后验概率密度值，并绘制图像保存为histo_analytical.png。\n",
    "6. 总结\n",
    "该代码展示了如何使用Seaborn和Matplotlib绘制直方图，并将其保存到本地文件。\n",
    "还展示了如何在贝叶斯推断中计算后验分布，使用简单的贝叶斯公式结合观测数据对均值mu进行更新，并绘制了后验分布。\n",
    "总体来说，代码中包含了可视化数据、计算和展示贝叶斯后验的过程。\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk')\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "data = np.random.randn(200)\n",
    "\n",
    "#histogram using seaborn (sns)\n",
    "ax = plt.subplot()\n",
    "sns.distplot(data, kde=True, ax=ax) # smooth using KDE: https://en.wikipedia.org/wiki/Kernel_density_estimation\n",
    "_ = ax.set(title='Histogram of observed data', xlabel='x', ylabel='frequency');\n",
    "plt.tight_layout()\n",
    "plt.savefig('histo_seaborn.png')\n",
    "plt.clf()\n",
    "\n",
    "#plot using matplotlib\n",
    "# An \"interface\" to matplotlib.axes.Axes.hist() method\n",
    "n, bins, patches = plt.hist(x=data, bins='auto', color='#0504aa', alpha=0.7, rwidth=0.85)\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('frequency')\n",
    "plt.tight_layout()\n",
    "plt.savefig('histo_matplotlib.png')\n",
    "plt.clf()\n",
    "\n",
    "def calc_posterior_analytical(data, x, mu_0, sigma_0):\n",
    "    sigma = 1.\n",
    "    n = len(data)\n",
    "    mu_post = (mu_0 / sigma_0**2 + data.sum() / sigma**2) / (1. / sigma_0**2 + n / sigma**2)\n",
    "    sigma_post = (1. / sigma_0**2 + n / sigma**2)**-1\n",
    "    return norm(mu_post, np.sqrt(sigma_post)).pdf(x)\n",
    "\n",
    "ax = plt.subplot()\n",
    "x = np.linspace(-1, 1, 50)\n",
    "\n",
    "posterior_analytical = calc_posterior_analytical(data, x, 0., 1.)\n",
    "print(posterior_analytical)\n",
    "ax.plot(x, posterior_analytical)\n",
    "ax.set(xlabel='mu', ylabel='belief', title='Analytical posterior');\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig('histo_analytical.png')\n",
    "plt.clf()\n",
    "\n",
    " "
   ],
   "id": "94a16553310f6b70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#source https://rdrr.io/cran/MCMCpack/man/MCMClogit.html\n",
    "'''\n",
    "这段代码使用 MCMCpack 包来进行逻辑回归的贝叶斯推断。\n",
    "\n",
    "首先，加载 MCMCpack 包，并使用示例数据集 birthwt。代码中的每个示例使用 MCMClogit 函数对低出生体重(low)进行建模，预测变量包括母亲的年龄(age)、种族(race，因子化)和吸烟状态(smoke)。\n",
    "\n",
    "默认先验是一个不适当的均匀分布（Improper Uniform Prior）。\n",
    "使用多元正态分布作为先验，其中均值为0，方差为0.001。\n",
    "使用用户定义的独立柯西分布先验，定义了一个 logpriorfun 函数，返回贝塔参数的柯西先验对数值。\n",
    "定义带额外参数的独立柯西分布先验，包括位置(location)和尺度(scale)参数。\n",
    "每个示例中，代码拟合模型(MCMClogit)，并用 plot 和 summary 函数来检查模型的后验分布和总结结果。\n",
    "'''\n",
    "\n",
    "library(MCMCpack)\n",
    "\n",
    "   ## Not run: \n",
    "   ## default improper uniform prior\n",
    "   data(birthwt)\n",
    "   posterior <- MCMClogit(low~age+as.factor(race)+smoke, data=birthwt)\n",
    "   plot(posterior)\n",
    "   summary(posterior)\n",
    "\n",
    "\n",
    "   ## multivariate normal prior\n",
    "   data(birthwt)\n",
    "   posterior <- MCMClogit(low~age+as.factor(race)+smoke, b0=0, B0=.001,\n",
    "                          data=birthwt)\n",
    "   plot(posterior)\n",
    "   summary(posterior)\n",
    "\n",
    "\n",
    "   ## user-defined independent Cauchy prior\n",
    "   logpriorfun <- function(beta){\n",
    "     sum(dcauchy(beta, log=TRUE))\n",
    "   }\n",
    "\n",
    "   posterior <- MCMClogit(low~age+as.factor(race)+smoke,\n",
    "                          data=birthwt, user.prior.density=logpriorfun,\n",
    "                          logfun=TRUE)\n",
    "   plot(posterior)\n",
    "   summary(posterior)\n",
    "\n",
    "\n",
    "   ## user-defined independent Cauchy prior with additional args\n",
    "   logpriorfun <- function(beta, location, scale){\n",
    "     sum(dcauchy(beta, location, scale, log=TRUE))\n",
    "   }\n",
    "\n",
    "   posterior <- MCMClogit(low~age+as.factor(race)+smoke,\n",
    "                          data=birthwt, user.prior.density=logpriorfun,\n",
    "                          logfun=TRUE, location=0, scale=10)\n",
    "   plot(posterior)\n",
    "   summary(posterior)\n",
    "\n",
    "\n",
    "   \n",
    "## End(Not run)\n"
   ],
   "id": "c59268a4c603a13",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Week 7",
   "id": "62be7106c4e4969e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "'''\n",
    "导入必要的库：\n",
    "\n",
    "numpy 和 pandas 用于数据处理。\n",
    "eps 代表一个很小的浮点值，用于防止数值为零的除法错误。\n",
    "log2 用于计算以 2 为底的对数（熵的定义需要用到对数）。\n",
    "定义 find_entropy 函数：\n",
    "\n",
    "find_entropy(df) 计算传入数据帧 df 的熵。\n",
    "Class = df.keys()[-1] 获取数据帧中最后一列的名称，表示目标变量（在这里是“play”列）。\n",
    "values = df[Class].unique() 获取目标变量中的所有唯一值（在这里是 \"yes\" 和 \"no\"）。\n",
    "遍历 values，计算每个唯一值的频率（fraction），并使用熵公式 -fraction * log2(fraction) 计算熵值。\n",
    "最终返回目标列的总熵。\n",
    "创建数据集：\n",
    "\n",
    "使用不同的天气属性（outlook、temp、humidity、windy）和目标变量 play 来构建数据集。\n",
    "这些属性用逗号分隔的字符串表示，通过 .split(',') 转化为列表。\n",
    "将所有属性组合为字典，使用 pd.DataFrame() 将其转换为数据帧 df。\n",
    "打印数据帧和熵：\n",
    "\n",
    "print(df) 打印数据集以查看数据的结构。\n",
    "print(find_entropy(df)) 调用熵计算函数，并打印计算得到的熵。\n",
    "'''\n",
    "#source: https://medium.com/@lope.ai/decision-trees-from-scratch-using-id3-python-coding-it-up-6b79e3458de4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "eps = np.finfo(float).eps\n",
    "from numpy import log2 as log\n",
    "\n",
    "\n",
    "def find_entropy(df):\n",
    "    Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
    "    print(df.keys(), ' list of attributes')\n",
    "    print(Class, ' is Class')\n",
    "    entropy = 0\n",
    "    values = df[Class].unique()\n",
    "    for value in values:\n",
    "        fraction = df[Class].value_counts()[value]/len(df[Class])\n",
    "        entropy += -fraction*np.log2(fraction)\n",
    "        print(df[Class].value_counts()[value], fraction, entropy, value)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "outlook = 'overcast,overcast,overcast,overcast,rainy,rainy,rainy,rainy,rainy,sunny,sunny,sunny,sunny,sunny'.split(',')\n",
    "temp = 'hot,cool,mild,hot,mild,cool,cool,mild,mild,hot,hot,mild,cool,mild'.split(',')\n",
    "humidity = 'high,normal,high,normal,high,normal,normal,normal,high,high,high,high,normal,normal'.split(',')\n",
    "windy = 'FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,TRUE'.split(',')\n",
    "play = 'yes,yes,yes,yes,yes,yes,no,yes,no,no,no,no,yes,yes'.split(',')\n",
    "\n",
    "dataset ={'outlook':outlook,'temp':temp,'humidity':humidity,'windy':windy,'play':play}\n",
    "df = pd.DataFrame(dataset,columns=['outlook','temp','humidity','windy','play'])\n",
    "\n",
    "print(df)\n",
    "print(find_entropy(df))"
   ],
   "id": "73d0c64af7d3a767"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "'''\n",
    "\n",
    "这段代码实现了ID3算法，从头开始构建决策树，找出每个属性的最佳划分方式，下面我来逐步解释：\n",
    "\n",
    "导入库和初始化：\n",
    "\n",
    "导入 numpy 和 pandas 以用于数值运算和数据处理。\n",
    "eps 是一个非常小的值，用于防止数值为0时导致的除零错误。\n",
    "log2 计算以2为底的对数，用于计算熵。\n",
    "find_entropy(df) 函数：\n",
    "\n",
    "计算整个数据集的熵。\n",
    "首先获取目标变量（在这里是 'play' 列）的名称，然后对目标变量中每个唯一值计算其频率。\n",
    "熵是通过 -fraction * log2(fraction) 的公式计算的，用来衡量目标变量的纯度。\n",
    "find_entropy_attribute(df, attribute) 函数：\n",
    "\n",
    "计算给定属性的条件熵，用于评估在某个属性的基础上划分数据集后的混乱程度。\n",
    "首先，获取目标变量（如 'play' 列）和属性的所有唯一值。\n",
    "对于每个属性值，计算该属性值下目标变量的熵。\n",
    "通过对所有属性值计算并求和，得到整个属性的条件熵。\n",
    "find_winner(df) 函数：\n",
    "\n",
    "找到信息增益最高的属性，这就是在当前节点上最佳的划分属性。\n",
    "信息增益的计算方式是通过目标变量的总熵减去给定属性的条件熵。\n",
    "将所有属性的信息增益放入列表中，使用 np.argmax(IG) 找到信息增益最大的属性并返回。\n",
    "创建数据集：\n",
    "\n",
    "通过字符串列表创建数据集，包括 outlook（天气情况）、temp（温度）、humidity（湿度）、windy（是否有风）、play（是否适合玩耍）。\n",
    "使用 pd.DataFrame() 将这些列表组合成一个数据帧 df。\n",
    "找出最佳属性：\n",
    "\n",
    "调用 find_winner(df) 函数获取信息增益最大的属性，即用于划分数据集的节点属性。\n",
    "打印找到的节点属性（如 outlook）。\n",
    "获取该属性的所有唯一值：\n",
    "\n",
    "使用 np.unique(df[node]) 获取这个属性的所有可能取值。\n",
    "'''\n",
    "#source: https://medium.com/@lope.ai/decision-trees-from-scratch-using-id3-python-coding-it-up-6b79e3458de4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "eps = np.finfo(float).eps\n",
    "from numpy import log2 as log\n",
    "\n",
    "\n",
    "def find_entropy(df):\n",
    "    Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
    "    entropy = 0\n",
    "    values = df[Class].unique()\n",
    "    for value in values:\n",
    "        fraction = df[Class].value_counts()[value]/len(df[Class])\n",
    "        entropy += -fraction*np.log2(fraction)\n",
    "        #print( entropy, value)\n",
    "    return entropy\n",
    "\n",
    "def find_entropy_attribute(df,attribute):\n",
    "  Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
    "  target_variables = df[Class].unique()  #This gives all 'Yes' and 'No'\n",
    "  variables = df[attribute].unique()    #This gives different features in that attribute (like 'Hot','Cold' in Temperature)\n",
    "  entropy2 = 0\n",
    "  for variable in variables:\n",
    "      entropy = 0\n",
    "      for target_variable in target_variables:\n",
    "          num = len(df[attribute][df[attribute]==variable][df[Class] ==target_variable])\n",
    "          den = len(df[attribute][df[attribute]==variable])\n",
    "          fraction = num/(den+eps)\n",
    "          entropy += -fraction*log(fraction+eps)\n",
    "      fraction2 = den/len(df)\n",
    "      entropy2 += -fraction2*entropy\n",
    "\n",
    "  return abs(entropy2)\n",
    "\n",
    "\n",
    "def find_winner(df):\n",
    "    Entropy_att = []\n",
    "    IG = []\n",
    "    for key in df.keys()[:-1]:\n",
    "        Entropy_att.append(find_entropy_attribute(df,key))\n",
    "        gain = find_entropy(df)-find_entropy_attribute(df,key)\n",
    "        print(find_entropy(df), find_entropy_attribute(df,key), gain, key, ' gain, key')\n",
    "        IG.append(gain)\n",
    "        print(key, ' key')\n",
    "    return df.keys()[:-1][np.argmax(IG)]\n",
    "  \n",
    "\n",
    "\n",
    "outlook = 'overcast,overcast,overcast,overcast,rainy,rainy,rainy,rainy,rainy,sunny,sunny,sunny,sunny,sunny'.split(',')\n",
    "temp = 'hot,cool,mild,hot,mild,cool,cool,mild,mild,hot,hot,mild,cool,mild'.split(',')\n",
    "humidity = 'high,normal,high,normal,high,normal,normal,normal,high,high,high,high,normal,normal'.split(',')\n",
    "windy = 'FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,TRUE'.split(',')\n",
    "play = 'yes,yes,yes,yes,yes,yes,no,yes,no,no,no,no,yes,yes'.split(',')\n",
    "\n",
    "dataset ={'outlook':outlook,'temp':temp,'humidity':humidity,'windy':windy,'play':play}\n",
    "df = pd.DataFrame(dataset,columns=['outlook','temp','humidity','windy','play'])\n",
    "\n",
    "\n",
    "#Get attribute with maximum information gain\n",
    "node = find_winner(df)\n",
    "print(node, ' node')\n",
    "\n",
    "#Get distinct value of that attribute e.g Salary is node and Low,Med and High are values\n",
    "attValue = np.unique(df[node])\n",
    "print(attValue, ' attValue')\n"
   ],
   "id": "c750466e80dd62c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "'''\n",
    "这段代码实现了ID3算法来从头构建决策树，用于对数据进行分类。它选择信息增益最高的属性来构建决策树的节点，并通过递归方式来不断划分数据，直到数据集完全纯净为止。下面是代码的详细解释：\n",
    "\n",
    "导入库和初始化\n",
    "导入 numpy 和 pandas，用于数值运算和数据处理。\n",
    "eps 是一个很小的数值，用于避免除以零的情况。\n",
    "使用 log2 来计算熵。\n",
    "1. find_entropy(df) 函数\n",
    "功能：计算目标变量（例如 play 列）的熵，用于衡量数据集的混乱程度。\n",
    "步骤：\n",
    "获取目标变量（最后一列）的名称。\n",
    "计算每个类别的频率，并计算熵（公式为 -fraction * log2(fraction)）。\n",
    "2. find_entropy_attribute(df, attribute) 函数\n",
    "功能：计算给定属性的条件熵，用于评估数据集根据该属性划分后的纯净度。\n",
    "步骤：\n",
    "获取目标变量和给定属性的所有唯一值。\n",
    "对于每个属性值，计算目标变量的各类频率，并计算熵。\n",
    "最后累加各个属性值对应的熵，得到整个属性的条件熵。\n",
    "3. find_winner(df) 函数\n",
    "功能：找到信息增益最大的属性，即用来划分数据集的最优属性。\n",
    "步骤：\n",
    "计算数据集的总熵。\n",
    "遍历数据帧中的每个属性，计算其条件熵和信息增益。\n",
    "找到信息增益最高的属性并返回其名称。\n",
    "4. get_subtable(df, node, value) 函数\n",
    "功能：根据节点属性值获取对应的数据子集。\n",
    "步骤：\n",
    "使用条件筛选，返回包含该属性值的数据子集，并重新索引。\n",
    "5. buildTree(df, tree=None) 函数\n",
    "功能：递归地构建决策树。\n",
    "步骤：\n",
    "首先，找到信息增益最大的属性，即最佳划分属性（node）。\n",
    "获取该属性的所有唯一值，创建一个空字典用于构建树。\n",
    "对于每个属性值，获取对应的子数据集（subtable），并检查它的纯净性：\n",
    "如果子数据集纯净（即目标变量只有一个唯一值），将该值作为树的叶节点。\n",
    "如果不纯净，递归调用 buildTree 来进一步划分。\n",
    "最后返回构建完成的树。\n",
    "数据集\n",
    "创建了包含 outlook（天气情况）、temp（温度）、humidity（湿度）、windy（有无风）和 play（是否适合玩耍）的数据集。\n",
    "使用这些属性构建一个数据帧 df，并打印出来查看其结构。\n",
    "构建决策树\n",
    "使用 buildTree(df) 函数构建决策树，并将结果存储在变量 tree 中。\n",
    "打印树的结构。\n",
    "示例输出说明\n",
    "数据集：首先打印出整个数据集的结构。\n",
    "节点选择：每次递归构建树时，会打印出选择的节点（最佳属性）及其属性值。\n",
    "子集纯净性：对于每个子集，打印其目标变量的唯一值。\n",
    "决策树结构：最后打印构建完成的树。\n",
    "'''\n",
    "#source: https://medium.com/@lope.ai/decision-trees-from-scratch-using-id3-python-coding-it-up-6b79e3458de4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "eps = np.finfo(float).eps # The difference between 1.0 and the next smallest representable float larger than 1.0. For example, for 64-bit binary floats in the IEEE-754 standard, eps = 2**-52, approximately 2.22e-16.\n",
    "from numpy import log2 as log\n",
    "\n",
    "\n",
    "def find_entropy(df):\n",
    "    Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
    "    entropy = 0\n",
    "    values = df[Class].unique()\n",
    "    for value in values:\n",
    "        fraction = df[Class].value_counts()[value]/len(df[Class])\n",
    "        entropy += -fraction*np.log2(fraction)\n",
    "        #print( entropy, value)\n",
    "    return entropy\n",
    "\n",
    "def find_entropy_attribute(df,attribute):\n",
    "  Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
    "  target_variables = df[Class].unique()  #This gives all 'Yes' and 'No'\n",
    "  variables = df[attribute].unique()    #This gives different features in that attribute (like 'Hot','Cold' in Temperature)\n",
    "  sum_entropy = 0\n",
    "  \n",
    "  for variable in variables:\n",
    "      entropy = 0\n",
    "      \n",
    "      for target_variable in target_variables:\n",
    "          num = len(df[attribute] [df[attribute] == variable] [df[Class] == target_variable]) # 'num' for numerator ... Count how many items in df[attribute] for each variable and target variable combination\n",
    "          den = len(df[attribute] [df[attribute] == variable]) # 'den' for denominator ... Count how many items in df[attribute] for each variable\n",
    "          fraction_target = num / (den + eps) # For each variable in df[attribute], the proportion where the target variable is a specific result ... Seems that eps is added to avoid dividing by zero\n",
    "          entropy += -fraction_target * log(fraction_target + eps) # Adds up entropy calcs for each target variable within the attribute variable\n",
    "          \n",
    "      fraction_attribute = den / len(df) \n",
    "      sum_entropy += fraction_attribute * entropy # Once the entropies for the each target within the attribute variable are calculated they are multiplied by the fraction that the attribute represents of all attribute combinations\n",
    "\n",
    "  return sum_entropy # for some reason this code added -fraction_attribute to sum_entropy then got the abs of the result ... not sure why since fractions and entropy are always positive\n",
    "\n",
    "\n",
    "def find_winner(df):\n",
    "    Entropy_att = []\n",
    "    IG = []\n",
    "    \n",
    "    overall_entropy = find_entropy(df)\n",
    "    #print('Overall entropy: ', overall_entropy)\n",
    "    \n",
    "    for key in df.keys()[:-1]:\n",
    "        \n",
    "        attribute_entropy = find_entropy_attribute(df,key)\n",
    "        Entropy_att.append(attribute_entropy) # recorded in a list but not used\n",
    "        \n",
    "        gain = overall_entropy - attribute_entropy\n",
    "        IG.append(gain) # used to index largest result\n",
    "        \n",
    "        #print('Attribute: ', key) \n",
    "        #print('Entropy: ', attribute_entropy, '  Gain: ', gain) \n",
    "        \n",
    "    return df.keys()[:-1][np.argmax(IG)] # returns the key (attribute name) indexed to have the largest gain result\n",
    "  \n",
    "\n",
    "def get_subtable(df, node, value):\n",
    "  return df[df[node] == value].reset_index(drop=True)\n",
    "\n",
    "\n",
    "def buildTree(df,tree=None): \n",
    "    Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
    "    #Here we build our decision tree\n",
    "\n",
    "    #Get attribute with maximum information gain\n",
    "    node = find_winner(df)    \n",
    "    \n",
    "    #Get distinct values of that attribute e.g Salary is node and Low, Med and High are values\n",
    "    attValues = np.unique(df[node])\n",
    "    \n",
    "    print('Winning attribute node: ', node, attValues)\n",
    "    \n",
    "    #Create an empty dictionary to create tree    \n",
    "    if tree is None:                    \n",
    "        tree = {}\n",
    "        tree[node] = {}\n",
    "    \n",
    "    #We make loop to construct a tree by calling this function recursively. \n",
    "    #In this we check if the subset is pure and stops if it is pure. \n",
    "    \n",
    "    for value in attValues:\n",
    "        \n",
    "        subtable = get_subtable(df, node, value)\n",
    "        print('\\nSubtable: \\n',subtable)\n",
    "        \n",
    "        class_values = subtable[Class].unique()\n",
    "        print('Values:', class_values)\n",
    "        \n",
    "        #clValue, counts = np.unique(subtable, return_counts=True)    # could be a bug here                    \n",
    "        #print('clValue: ',clValue)\n",
    "        #print('counts: ',counts)\n",
    "        \n",
    "        if len(class_values) == 1:#Checking purity of subset #values instead of counts\n",
    "            tree[node][value] = class_values[0]    #values instead of clValue                                               \n",
    "        else: \n",
    "            #there is a bug here   (need to compare with code here: https://www.python-course.eu/Decision_Trees.php)    \n",
    "            tree[node][value] = buildTree(subtable) #Calling the function recursively \n",
    "    \n",
    "                   \n",
    "    return tree\n",
    "\n",
    "\n",
    "outlook = 'overcast,overcast,overcast,overcast,rainy,rainy,rainy,rainy,rainy,sunny,sunny,sunny,sunny,sunny'.split(',')\n",
    "temp = 'hot,cool,mild,hot,mild,cool,cool,mild,mild,hot,hot,mild,cool,mild'.split(',')\n",
    "humidity = 'high,normal,high,normal,high,normal,normal,normal,high,high,high,high,normal,normal'.split(',')\n",
    "windy = 'FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,TRUE'.split(',')\n",
    "play = 'yes,yes,yes,yes,yes,yes,no,yes,no,no,no,no,yes,yes'.split(',')\n",
    "\n",
    "dataset = {'outlook':outlook,'temp':temp,'humidity':humidity,'windy':windy,'play':play}\n",
    "df = pd.DataFrame(dataset,columns=['outlook','temp','humidity','windy','play'])\n",
    "print(df)\n",
    "\n",
    "tree = buildTree(df)\n",
    "print(tree)"
   ],
   "id": "4e6a128092993fc2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Week 8",
   "id": "ba9cd5f5aa1e814e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "'''\n",
    "这段代码实现了一个基于 AdaBoost 算法的分类器，以下是对各部分的解释：\n",
    "\n",
    "导入库和定义辅助函数：\n",
    "\n",
    "numpy 用于数值计算。\n",
    "DecisionTreeClassifier 是一个单层决策树（即弱分类器）。\n",
    "AdaBoostClassifier 是一个集成学习库实现，虽然未直接使用它。\n",
    "辅助函数 I(flag) 和 sign(x) 分别用于布尔转换和符号判断。\n",
    "自定义 AdaBoost 类：\n",
    "\n",
    "__init__() 方法：初始化 n_estimators，即弱分类器数量，同时创建一个存储这些分类器的列表。\n",
    "fit() 方法：训练模型。\n",
    "将输入数据 X 转换为浮点类型，初始化样本权重 w。\n",
    "使用多个弱分类器（DecisionTreeClassifier），逐次进行训练，并根据分类误差来更新样本权重，以便让后续分类器更关注难以分类的样本。\n",
    "计算每个弱分类器的权重 AlphaM，并更新样本权重 w。\n",
    "将弱分类器及其权重存储到模型列表中。\n",
    "predict() 方法：预测新样本。\n",
    "利用所有弱分类器的加权预测结果，汇总为最终的分类结果。\n",
    "测试模型：\n",
    "\n",
    "使用 make_classification 生成测试数据。\n",
    "标签转换：将 y 中为 0 的样本标签转换为 -1，以符合 AdaBoost 算法的要求。\n",
    "实例化并训练自定义的 AdaBoost 模型。\n",
    "预测数据，并计算模型的性能和混淆矩阵。\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "def I(flag):\n",
    "    return 1 if flag else 0\n",
    "\n",
    "def sign(x):\n",
    "    return abs(x)/x if x!=0 else 1       \n",
    "\n",
    "class AdaBoost:\n",
    "    \n",
    "    def __init__(self,n_estimators=50):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.models = [None]*n_estimators\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        \n",
    "        X = np.float64(X)\n",
    "        N = len(y)\n",
    "        w = np.array([1/N for i in range(N)])\n",
    "        \n",
    "        for m in range(self.n_estimators):\n",
    "            \n",
    "            Gm = DecisionTreeClassifier(max_depth=1).fit(X,y,sample_weight=w).predict\n",
    "                        \n",
    "            errM = sum([w[i]*I(y[i]!=Gm(X[i].reshape(1,-1))) for i in range(N)])/sum(w)\n",
    " \n",
    "            AlphaM = np.log((1-errM)/errM)\n",
    "            \n",
    "            w = [w[i]*np.exp(AlphaM*I(y[i]!=Gm(X[i].reshape(1,-1)))) for i in range(N)] \n",
    "            \n",
    "            \n",
    "            self.models[m] = (AlphaM,Gm)\n",
    "\n",
    "    def predict(self,X):\n",
    "        \n",
    "        y = 0\n",
    "        for m in range(self.n_estimators):\n",
    "            AlphaM,Gm = self.models[m]\n",
    "            y += AlphaM*Gm(X)\n",
    "        signA = np.vectorize(sign)\n",
    "        y = np.where(signA(y)==-1,-1,1)\n",
    "        return y\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix as CM\n",
    "\n",
    "x,y = make_classification(n_samples=217)\n",
    "'''\n",
    "As for our implementaion of AdaBoost \n",
    "y needs to be in {-1,1}\n",
    "'''\n",
    "y = np.where(y==0,-1,1)\n",
    "\n",
    "clf = AdaBoost(n_estimators=5) # try 5 10 50 and press Run over and over again\n",
    "clf.fit(x,y)\n",
    "y_pred = clf.predict(x)\n",
    "\n",
    "\n",
    "print(\"Performance:\",100*sum(y_pred==y)/len(y))\n",
    "print(\"Confusion Matrix:\",CM(y,y_pred))"
   ],
   "id": "bad9b46ae32ccf48"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "'''\n",
    "\n",
    "这段代码通过手动实现了一种类似于梯度提升（Gradient Boosting）的过程，用多个决策树来拟合数据。这是对梯度提升树的基本原理的演示。以下是详细的解释：\n",
    "\n",
    "生成数据：\n",
    "\n",
    "使用 numpy 生成随机数（设置随机种子为 42 以确保结果可复现）。\n",
    "X 是一个包含 100 个样本的特征，每个值在 -0.5 到 0.5 之间。\n",
    "y 是目标值，它的生成是基于 3 * X^2 的非线性函数，加上了一点随机噪声。\n",
    "拟合多个回归树：\n",
    "\n",
    "第一个决策树 tree_reg1 使用 max_depth=2 进行拟合，拟合数据集 (X, y)。\n",
    "残差计算：计算第一次拟合后的残差，即 y2 = y - tree_reg1.predict(X)，它代表原始目标值和模型预测之间的差异。\n",
    "第二个决策树 tree_reg2 用来拟合残差 y2，同样使用最大深度为 2。\n",
    "再次残差计算：计算第二次拟合后的残差 y3 = y2 - tree_reg2.predict(X)，代表第二个模型拟合后的差异。\n",
    "第三个决策树 tree_reg3 用来拟合第二次残差 y3。\n",
    "预测新样本：\n",
    "\n",
    "定义一个新的样本点 X_new = [[0.8]]。\n",
    "使用每个回归树分别对 X_new 进行预测，并将预测值累加起来，即 y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))。\n",
    "累加的过程相当于各个树的预测值进行加权和，从而得到最终的预测结果，这种方法类似于梯度提升。\n",
    "打印结果：\n",
    "\n",
    "打印了每个回归树对 X_new 的预测结果。\n",
    "打印了最终的梯度提升预测结果。\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) - 0.5\n",
    "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg1.fit(X, y)\n",
    "\n",
    "y2 = y - tree_reg1.predict(X)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg2.fit(X, y2)\n",
    "\n",
    "y3 = y2 - tree_reg2.predict(X)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg3.fit(X, y3)\n",
    "\n",
    "X_new = np.array([[0.8]])\n",
    "\n",
    "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))\n",
    "\n",
    "\n",
    "print('tree_reg1.predict : ', tree_reg1.predict(X_new) )\n",
    "print('tree_reg2.predict : ', tree_reg2.predict(X_new) )\n",
    "print('tree_reg3.predict : ', tree_reg3.predict(X_new) )\n",
    "print('---------- ------------')\n",
    "print('Gradient Boosting: ', y_pred )\n",
    "print('---------- ------------')\n"
   ],
   "id": "ef506ed42ee6714a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "'''\n",
    "这段代码比较了多种单一模型与一个堆叠（stacking）集成模型的分类性能。以下是代码的逐步解释：\n",
    "\n",
    "导入库：导入了多个必要的库来处理数据集、评估模型、以及实现不同的分类算法。\n",
    "\n",
    "数据集生成 (get_dataset)：使用 make_classification 生成一个包含 1000 个样本、20 个特征的合成分类数据集，其中 15 个特征是信息性的，5 个是冗余特征。\n",
    "\n",
    "定义堆叠模型 (get_stacking)：\n",
    "\n",
    "定义了 5 个基础模型（逻辑回归、KNN、决策树、SVM、朴素贝叶斯）作为底层学习器。\n",
    "使用逻辑回归作为元学习器，将基础模型的输出进行学习和融合。\n",
    "最终定义一个堆叠集成模型 StackingClassifier，通过交叉验证 (cv=5) 进一步增强性能。\n",
    "获取所有要评估的模型 (get_models)：定义了 5 个单独的分类器和一个堆叠模型，总共 6 个模型，存储在一个字典中。\n",
    "\n",
    "模型评估 (evaluate_model)：\n",
    "\n",
    "使用 RepeatedStratifiedKFold 进行 10 折交叉验证（重复 3 次），确保模型评估更加稳健。\n",
    "计算每个模型在交叉验证中的准确率，并返回分数列表。\n",
    "评估和比较模型：\n",
    "\n",
    "使用定义的数据集和模型列表，对每个模型进行交叉验证评估，并计算平均准确率和标准差。\n",
    "输出每个模型的评估结果，显示模型的名称、平均准确率、以及标准差。\n",
    "可视化比较：\n",
    "\n",
    "使用 boxplot 绘制不同模型的准确率分布图，以便于比较模型性能差异。\n",
    "将图表保存为 stacked.png。\n",
    "'''\n",
    "\n",
    "# compare ensemble to each baseline classifier\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "\treturn X, y\n",
    "\n",
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "\t# define the base models\n",
    "\tlevel0 = list()\n",
    "\tlevel0.append(('lr', LogisticRegression()))\n",
    "\tlevel0.append(('knn', KNeighborsClassifier()))\n",
    "\tlevel0.append(('cart', DecisionTreeClassifier()))\n",
    "\tlevel0.append(('svm', SVC()))\n",
    "\tlevel0.append(('bayes', GaussianNB()))\n",
    "\t# define meta learner model\n",
    "\tlevel1 = LogisticRegression()\n",
    "\t# define the stacking ensemble\n",
    "\tmodel = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "\treturn model\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tmodels['lr'] = LogisticRegression()\n",
    "\tmodels['knn'] = KNeighborsClassifier()\n",
    "\tmodels['cart'] = DecisionTreeClassifier()\n",
    "\tmodels['svm'] = SVC()\n",
    "\tmodels['bayes'] = GaussianNB()\n",
    "\tmodels['stacking'] = get_stacking()\n",
    "\treturn models\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model, X, y)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.savefig('stacked.png')"
   ],
   "id": "5ca561abd63716d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Week 9",
   "id": "b22c4bbdbb34e7d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# SVD数学计算代码\n",
    "\n",
    "from numpy import array\n",
    "from numpy import diag\n",
    "from numpy import zeros\n",
    "from scipy.linalg import svd\n",
    "# define a matrix\n",
    "A = array([\n",
    "\t[1,2,3,4,5,6,7,8,9,10],\n",
    "\t[11,12,13,14,15,16,17,18,19,20],\n",
    "\t[21,22,23,24,25,26,27,28,29,30]])\n",
    "print(A)\n",
    "# Singular-value decomposition\n",
    "# A = USV (S为sigma,但是表示为一个向量而非矩阵，包含了sigma矩阵的全部对角元素)\n",
    "U, s, VT = svd(A)\n",
    "\n",
    "# 使用对角元素向量s构建sigma矩阵\n",
    "# create m x n Sigma matrix\n",
    "Sigma = zeros((A.shape[0], A.shape[1]))\n",
    "# populate Sigma with n x n diagonal matrix\n",
    "Sigma[:A.shape[0], :A.shape[0]] = diag(s)\n",
    "\n",
    "# 特征选择，选择sigma的前两列，V的前两行\n",
    "# select\n",
    "n_elements = 2\n",
    "Sigma = Sigma[:, :n_elements]\n",
    "VT = VT[:n_elements, :]\n",
    "\n",
    "# 点乘，B是原矩阵A的一个低秩近似\n",
    "# reconstruct\n",
    "B = U.dot(Sigma.dot(VT))\n",
    "print(B)\n",
    "\n",
    "# SVD分解结果为T，有两种计算方法，结果一致\n",
    "# transform\n",
    "T = U.dot(Sigma)\n",
    "print(T)\n",
    "T = A.dot(VT.T)\n",
    "print(T)\n",
    "\n",
    "#Running the example first prints the defined matrix then the reconstructed\n",
    "# approximation, followed by two equivalent transforms of the original matrix.\n",
    "\n",
    "print(' Truncated SVD')\n",
    "#Truncated SVD\n",
    "\n",
    "#The TruncatedSVD class can be created in which you must specify the number\n",
    "# of desirable features or components to select, e.g. 2. Once created, \n",
    "#you can fit the transform (e.g. calculate V^Tk) by calling the fit() \n",
    "#function, then apply it to the original matrix by calling the transform() \n",
    "#function. The result is the transform of A called T above.\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# define array\n",
    "A = array([\n",
    "\t[1,2,3,4,5,6,7,8,9,10],\n",
    "\t[11,12,13,14,15,16,17,18,19,20],\n",
    "\t[21,22,23,24,25,26,27,28,29,30]])\n",
    "print(A)\n",
    "# svd\n",
    "svd = TruncatedSVD(n_components=2)\n",
    "svd.fit(A)\n",
    "result = svd.transform(A)\n",
    "print(result)"
   ],
   "id": "be6a503b1354f3dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 同理，只是这段代码用了np\n",
    "import numpy as np\n",
    "U, s, Vt = np.linalg.svd(A)\n",
    "W2 = Vt.T[:, :2]\n",
    "X2D = A.dot(W2)"
   ],
   "id": "3bb848a959e11f90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 增量PCA\n",
    "\n",
    "# Authors: Kyle Kastner\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "\n",
    "# 加载数据\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "n_components = 2\n",
    "ipca = IncrementalPCA(n_components=n_components, batch_size=10)\n",
    "X_ipca = ipca.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "print(X_ipca, ' X_ipca')\n",
    "\n",
    "colors = ['navy', 'turquoise', 'darkorange']\n",
    "\n",
    "for X_transformed, title in [(X_ipca, \"Incremental PCA\"), (X_pca, \"PCA\")]:\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for color, i, target_name in zip(colors, [0, 1, 2], iris.target_names):\n",
    "        plt.scatter(X_transformed[y == i, 0], X_transformed[y == i, 1],\n",
    "                    color=color, lw=2, label=target_name)\n",
    "\n",
    "    if True or \"Incremental\" in title:\n",
    "        err = np.abs(np.abs(X_pca) - np.abs(X_ipca)).mean()\n",
    "        plt.title(title + \" of iris dataset\\nMean absolute unsigned error \"\n",
    "                  \"%.6f\" % err)\n",
    "    else:\n",
    "        plt.title(title + \" of iris dataset\")\n",
    "    plt.legend(loc=\"best\", shadow=False, scatterpoints=1)\n",
    "    plt.axis([-4, 4, -1.5, 1.5])\n",
    "\n",
    "plt.savefig('ipca.png')\n"
   ],
   "id": "24ba456647a64fff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#K-Means 聚类算法\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "#style.use('ggplot')\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class K_Means:\n",
    "    def __init__(self, k=3, tol=0.01, max_iter=300):\n",
    "        self.k = k\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "        self.centroids = {}\n",
    "\n",
    "    def fit(self,data):\n",
    "\n",
    "\n",
    "        for i in range(self.k):\n",
    "            self.centroids[i] = data[i]\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            print(i, self.centroids, ' centroids')\n",
    "            self.classifications = {}\n",
    "\n",
    "            for i in range(self.k):\n",
    "                self.classifications[i] = []\n",
    "            \n",
    "            print(self.classifications, i, ' * ')\n",
    "\n",
    "            for featureset in data:\n",
    "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids] # check distance of every data point to every centroid\n",
    "                print(distances, featureset, ' dist - featureset')\n",
    "                classification = distances.index(min(distances)) # get index of centroid that best suits the data point\n",
    "                self.classifications[classification].append(featureset) # assign the centroid id to the data point\n",
    "            \n",
    "            print(self.classifications, i, ' + ')\n",
    "\n",
    "            prev_centroids = dict(self.centroids)\n",
    "\n",
    "            for classification in self.classifications:\n",
    "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
    "\n",
    "            optimized = True\n",
    "\n",
    "            for c in self.centroids: # update centroid position\n",
    "                original_centroid = prev_centroids[c]\n",
    "                current_centroid = self.centroids[c]\n",
    "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
    "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
    "                    optimized = False\n",
    "\n",
    "            if optimized:\n",
    "                break\n",
    "        return self.centroids\n",
    "\n",
    "    def predict(self,data):\n",
    "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
    "        classification = distances.index(min(distances))\n",
    "        return classification\n",
    "\n",
    "#main\n",
    "\n",
    "X = np.array([[1, 2],\n",
    "              [1.5, 1.8],\n",
    "              [5, 8 ],\n",
    "              [8, 8],\n",
    "              [1, 0.6],\n",
    "              [9,11],\n",
    "              [1,3],\n",
    "              [8,9],\n",
    "              [0,3],\n",
    "              [5,4],\n",
    "              [6,4],])\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], s=150)\n",
    "plt.savefig('data.png')\n",
    "print(X, ' data')\n",
    "\n",
    "colors = 10*[\"g\",\"r\",\"c\",\"b\",\"k\"]\n",
    "clf = K_Means()\n",
    "x = clf.fit(X)\n",
    "print(x, 'final centroids')\n",
    "\n",
    "for centroid in clf.centroids:\n",
    "    plt.scatter(clf.centroids[centroid][0], clf.centroids[centroid][1],\n",
    "                marker=\"o\", color=\"k\", s=150, linewidths=5)\n",
    "\n",
    "for classification in clf.classifications:\n",
    "    color = colors[classification]\n",
    "    for featureset in clf.classifications[classification]:\n",
    "        plt.scatter(featureset[0], featureset[1], marker=\"x\", color=color, s=150, linewidths=5)\n",
    "\n",
    "# in case we wish to test if data belongs to a cluster\n",
    "\n",
    "##unknowns = np.array([[1,3],\n",
    "##                     [8,9],\n",
    "##                     [0,3],\n",
    "##                     [5,4],\n",
    "##                     [6,4],])\n",
    "##\n",
    "##for unknown in unknowns:\n",
    "##    classification = clf.predict(unknown)\n",
    "##    plt.scatter(unknown[0], unknown[1], marker=\"*\", color=colors[classification], s=150, linewidths=5)\n",
    "##\n",
    "\n",
    "plt.savefig('kmeans.png')"
   ],
   "id": "ded843b9a4cdd29e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 软聚类代码\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "# Let's start by generating some blobs ---\n",
    "blob_centers = np.array(\n",
    "    [[ 0.2,  2.3],\n",
    "     [-1.5 ,  2.3],\n",
    "     [-2.8,  1.8],\n",
    "     [-2.8,  2.8],\n",
    "     [-2.8,  1.3]])\n",
    "blob_std = np.array([0.4, 0.3, 0.1, 0.1, 0.1])\n",
    "X, y = make_blobs(n_samples=2000, centers=blob_centers,\n",
    "                  cluster_std=blob_std, random_state=7)\n",
    "# ------- end of generating blobs ----- \n",
    "k = 5\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "y_pred = kmeans.fit_predict(X)\n",
    "\n",
    "# The following assigns new instances to the cluster whose centroid is closest\n",
    "X_new = np.array([[0, 2], [3, 2], [-3, 3], [-3, 2.5]])\n",
    "\n",
    "print('kmeans.transform(X_new):')\n",
    "print(kmeans.transform(X_new))\n",
    "\n"
   ],
   "id": "1bc91a220a5dbd8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 分层聚类算法\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#The next step is to import or create the dataset. In this example, we'll use the following example data:\n",
    "\n",
    "X = np.array([[5,3],\n",
    "    [10,15],\n",
    "    [15,12],\n",
    "    [24,10],\n",
    "    [30,30],\n",
    "    [85,70],\n",
    "    [71,80],\n",
    "    [60,78],\n",
    "    [70,55],\n",
    "    [80,91],])\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster = AgglomerativeClustering(n_clusters=2, linkage='ward')\n",
    "cluster.fit_predict(X) \n",
    "print(cluster.labels_)\n",
    "\n",
    "plt.scatter(X[:,0],X[:,1], c=cluster.labels_, cmap='rainbow')\n",
    "plt.savefig('clusters.png')\n",
    "\n"
   ],
   "id": "35428e0e46b459b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# DBSCAN聚类\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.datasets import make_moons\n",
    "import numpy as np\n",
    "\n",
    "X, y = make_moons(n_samples=1000, noise=0.05)\n",
    "print(X)\n",
    "dbscan = DBSCAN(eps=0.05, min_samples=5)\n",
    "dbscan.fit(X)\n",
    "print('dbscan.labels_[:10]: ', dbscan.labels_[:10])\n",
    "print('np.unique(dbscan.labels_): ', np.unique(dbscan.labels_))\n"
   ],
   "id": "a32c3210758b8411",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# DBSCAN 聚类\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Generate sample data\n",
    "# 生成样本数据\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "X, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4,\n",
    "                            random_state=0)\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# #############################################################################\n",
    "# Compute DBSCAN 计算聚类\n",
    "db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present. 计算簇数量和噪声点数量\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "# Homogeneity：同质性，所有簇只包含单一类别的样本的程度。\n",
    "# Completeness：完整性，所有同一类别的样本被分配到同一簇的程度。\n",
    "# V-measure：同质性和完整性的调和平均值。\n",
    "# Adjusted Rand Index (ARI)：调整后的兰德指数，衡量聚类与真实标签的一致性。\n",
    "# Adjusted Mutual Information (AMI)：调整后的互信息，衡量聚类结果和真实标签的信息共享程度。\n",
    "# Silhouette Coefficient：轮廓系数，衡量聚类结果的紧密性和分离性，值越接近 1，聚类效果越好。\n",
    "\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\"\n",
    "      % metrics.adjusted_rand_score(labels_true, labels))\n",
    "print(\"Adjusted Mutual Information: %0.3f\"\n",
    "      % metrics.adjusted_mutual_info_score(labels_true, labels))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, labels))\n",
    "\n",
    "# #############################################################################\n",
    "# Plot result\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Black removed and is used for noise instead.\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = X[class_member_mask & core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=14)\n",
    "\n",
    "    xy = X[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=6)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.savefig('DBC.png')"
   ],
   "id": "62f187c28111c12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Week 10",
   "id": "479c14fd9cedb336"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''这段代码描述了时间序列模型中应用的“反向传播时间”算法（Back Propagation Through Time, BPTT），用于训练递归神经网络（RNN）。算法通过展开网络来处理序列中的依赖关系，并根据误差对权重进行更新。具体步骤如下：\n",
    "\n",
    "将网络展开为包含 k 个实例的网络（即展开 k 个时间步）。\n",
    "反复执行以下步骤直到满足停止条件：\n",
    "初始化上下文向量 x 为零向量（表示当前上下文）。\n",
    "遍历训练序列，从时间步 t 开始，对所有时间步进行迭代。\n",
    "将展开网络的输入设置为当前上下文 x 和从时间 t 到 t+k-1 的输入数据 a[t], a[t+1], ..., a[t+k-1]。\n",
    "前向传播计算网络的输出 p，得到网络在时间步 t+k 的预测值。\n",
    "计算误差 e，即目标值 y[t+k] 与预测值 p 的差。\n",
    "通过整个展开的网络反向传播误差 e，计算每个时间步的误差对权重的影响。\n",
    "将网络展开后的每个实例的权重变化加和起来。\n",
    "更新模型的所有权重。\n",
    "使用当前时间步的输入 a[t] 和上下文 x 计算新的上下文，用于下一个时间步的输入。'''\n",
    "\n",
    "Back_Propagation_Through_Time(a, y)   // a[t] is the input at time t. y[t] is the output\n",
    "    Unfold the network to contain k instances of f\n",
    "    do until stopping criteria is met:\n",
    "        x := the zero-magnitude vector // x is the current context\n",
    "        for t from 0 to n − k do      // t is time. n is the length of the training sequence\n",
    "            Set the network inputs to x, a[t], a[t+1], ..., a[t+k−1]\n",
    "            p := forward-propagate the inputs over the whole unfolded network\n",
    "            e := y[t+k] − p;           // error = target − prediction\n",
    "            Back-propagate the error, e, back across the whole unfolded network\n",
    "            Sum the weight changes in the k instances of f together.\n",
    "            Update all the weights in f and g.\n",
    "            x := f(x, a[t]);           // compute the context for the next time-step"
   ],
   "id": "b5e1838b6bc9648b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''\n",
    "这段代码实现了一个递归神经网络（RNN）的前向传播（ForwardPass）和反向传播时间算法（BPTT，Back Propagation Through Time）。以下是对代码的逐步解释：\n",
    "\n",
    "前向传播函数 ForwardPass(self, sample, slide):\n",
    "\n",
    "该函数用于处理输入样本的前向传播，计算每层的输出。\n",
    "sample_time = sample[slide] 获取当前时间步的输入数据。\n",
    "第一层（输入层到隐藏层）的前向传播：\n",
    "将输入样本的特征值赋给 InlayerOutL0，保存在时间步 slide + 1 的输入中。\n",
    "使用输入层的输出和权重矩阵 W1 计算每个隐藏单元的加权和（weightsum）。\n",
    "使用上一时间步隐藏层状态 OutputSlideL1 和状态权重矩阵 StateW 计算当前状态贡献（StateWeightSum）。\n",
    "计算总的输入加权和减去偏置 B1，并使用激活函数（sigmoid）计算隐藏层输出。\n",
    "第二层（隐藏层到输出层）的前向传播：\n",
    "计算隐藏层的输出与权重矩阵 W2 的加权和（weightsum），并使用激活函数 sigmoid 计算最终输出。\n",
    "反向传播时间函数 BPTT(self):\n",
    "\n",
    "该函数实现了训练递归神经网络的“反向传播时间”算法。\n",
    "对于每个样本，初始化隐藏层的初始状态 StateOut，并准备误差存储 (ErL1) 以及前向传播输出存储 (OutputSlideL1 和 OutputSlideL2)。\n",
    "对于每个时间步，调用 ForwardPass 计算前向传播的输出。\n",
    "在完成整个序列的前向传播后，反向从最后时间步到第一个时间步，调用 BackwardPass 进行反向传播，以调整网络的权重。\n",
    "总体上，这段代码实现了一个具有递归连接的神经网络，它利用前向传播来计算每个时间步的输出，并使用反向传播时间（BPTT）算法来学习网络的权重和偏置，以便使模型能够更好地拟合训练数据。在 ForwardPass 中，隐藏层的状态不仅依赖于当前输入，还依赖于前一时间步的状态，因此能够捕捉到时间上的依赖关系。而 BPTT 则通过逐时间步地反向传播误差来更新网络参数。\n",
    "'''\n",
    "\n",
    "   # [t1 (f1, f2, f3), t2 (f1, f2, f3), t3 (f1, f2, f3)] ->t4  (FNN) \n",
    "\n",
    "#RNN\n",
    "   # [t1] - f1, f2, f3\n",
    "   # [t2] - f1, f2, f3\n",
    "   # [t3] - f1, f2, f3\n",
    "   # [t4] - f1 \n",
    "\n",
    "\n",
    "   def ForwardPass(self, sample,slide):\n",
    "        sample_time = sample[slide]\n",
    "        layer = 0 \n",
    "        weightsum = 0.0\n",
    "        StateWeightSum = 0.0\n",
    "        forwardout=0.0 \n",
    "        for row in range(0,self.Top[0]):\n",
    "            self.InlayerOutL0[slide+1][row] = sample_time[row]\n",
    "\n",
    "        for y in range(0, self.Top[1]):\n",
    "            for x in range(0, self.Top[0]):\n",
    "                weightsum += self.InlayerOutL0[slide+1][x] * self.W1[x,y]\n",
    "           \n",
    "            for x in range(0,self.Top[1]):\n",
    "                StateWeightSum += self.OutputSlideL1[slide][x] * self.StateW[x,y]\n",
    "            forwardout = (weightsum + StateWeightSum) - self.B1[y]\n",
    "          \n",
    "            self.OutputSlideL1[slide+1][y] = self.sigmoid(forwardout)            \n",
    "            weightsum=0\n",
    "            StateWeightSum=0\n",
    "\n",
    "        layer = 1 #   hidden layer to output\n",
    "        weightsum = 0.0\n",
    "        #print(self.out,end=' ')\n",
    "        for y in range(0, self.Top[layer+1]):\n",
    "            for x in range(0, self.Top[layer]):\n",
    "                weightsum  +=   self.OutputSlideL1[slide+1][x] * self.W2[x,y]\n",
    "                forwardout = (weightsum - self.B2[y])\n",
    "            self.OutputSlideL2[slide+1][y] = self.sigmoid(forwardout) \n",
    "            weightsum = 0.0\n",
    "            StateWeightSum=0.0       \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "    def BPTT(self):  \n",
    "        for i,sample in enumerate(self.Train_x): \n",
    "            self.StateOut = np.ones(self.Top[1])\n",
    "            self.ErL1 = np.zeros((len(sample)+1,self.Top[1])) # need to modify for multiple layers\n",
    "            self.OutputSlideL1 = np.zeros((len(sample)+1,self.Top[1]))\n",
    "            for x in range(0,self.Top[1]):\n",
    "                self.OutputSlideL1[0][x] = self.StateOut[x]\n",
    "            self.InlayerOutL0 = np.zeros((len(sample)+1,self.Top[0]))\n",
    "            self.OutputSlideL2 = np.zeros((len(sample)+1,self.Top[2]))\n",
    "            for slide in range(0,len(sample)):\n",
    "                self.ForwardPass(sample,slide)\n",
    "            for slide in range(len(sample),0,-1):\n",
    "                self.BackwardPass(sample,self.learn_rate,self.Train_y[i-1],slide)\n"
   ],
   "id": "4ccc254565965f57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "'''\n",
    "这段代码实现了一个简单的递归神经网络（RNN），以下是对代码的解释：\n",
    "\n",
    "类 RecurrentNetwork 的定义:\n",
    "\n",
    "__init__(self):\n",
    "初始化了类的一些参数，包括：\n",
    "hidden_state：初始隐藏状态矩阵为零，形状为 (3, 3)。\n",
    "W_hh：用于隐藏状态到隐藏状态的权重矩阵，随机初始化。\n",
    "W_xh：用于输入到隐藏状态的权重矩阵，随机初始化。\n",
    "W_hy：用于隐藏状态到输出的权重矩阵，随机初始化。\n",
    "Bh 和 By：分别是隐藏层和输出层的偏置，随机初始化。\n",
    "这些权重和偏置用于对输入进行线性变换，以计算新的隐藏状态和最终输出。\n",
    "前向传播函数 forward_prop(self, x):\n",
    "\n",
    "该函数接收一个输入 x，然后计算新的隐藏状态和输出。\n",
    "计算过程如下：\n",
    "通过 np.dot(self.hidden_state, self.W_hh) 计算上一时间步隐藏状态与权重矩阵的点积。\n",
    "通过 np.dot(x, self.W_xh) 计算输入向量与输入到隐藏层的权重矩阵的点积。\n",
    "上述两项加上隐藏层的偏置 Bh，通过 np.tanh() 激活函数计算新的隐藏状态。\n",
    "最后通过 self.W_hy.dot(self.hidden_state) + self.By 计算隐藏状态到输出层的输出。\n",
    "运行代码部分:\n",
    "\n",
    "初始化了一个输入向量 input_vector，大小为 (3, 3)，其元素均为 1。\n",
    "然后创建了 RecurrentNetwork 的一个实例 silly_network。\n",
    "使用 silly_network.forward_prop(input_vector) 三次调用前向传播函数，并打印输出。\n",
    "每次调用时，前向传播的结果都会不同，因为递归神经网络中的隐藏状态是不断更新的，它依赖于之前的时间步，这使得相同的输入在不同的时间步产生不同的输出。\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "class RecurrentNetwork(object):\n",
    "    \"\"\"When we say W_hh, it means a weight matrix that accepts a hidden state and produce a new hidden state.\n",
    "    Similarly, W_xh represents a weight matrix that accepts an input vector and produce a new hidden state. This\n",
    "    notation can get messy as we get more variables later on with LSTM and I simplify the notation a little bit in\n",
    "    LSTM notes.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.hidden_state = np.zeros((3, 3))\n",
    "        self.W_hh = np.random.randn(3, 3)\n",
    "        self.W_xh = np.random.randn(3, 3)\n",
    "        self.W_hy = np.random.randn(3, 3)\n",
    "        self.Bh = np.random.randn(3,)\n",
    "        self.By = np.random.rand(3,)\n",
    "\n",
    "    def forward_prop(self, x):\n",
    "        # The order of which you do dot product is entirely up to you. The gradient updates will take care itself\n",
    "        # as long as the matrix dimension matches up.\n",
    "        self.hidden_state =         return self.W_hy.dot(self.hidden_state) + self.By\n",
    "np.tanh(np.dot(self.hidden_state, self.W_hh) + np.dot(x, self.W_xh) + self.Bh)\n",
    "\n",
    "\n",
    "input_vector = np.ones((3, 3))\n",
    "print(input_vector, ' input vec')\n",
    "silly_network = RecurrentNetwork()\n",
    "\n",
    "\n",
    "# Notice that same input, but leads to different ouptut at every single time step.\n",
    "print(silly_network.forward_prop(input_vector))\n",
    "print(silly_network.forward_prop(input_vector))\n",
    "print(silly_network.forward_prop(input_vector))"
   ],
   "id": "dd24114d46e80d1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "'''\n",
    "加载和准备数据：\n",
    "\n",
    "使用Keras的imdb数据集加载电影评论，设置词汇表大小为5000个最常见单词。\n",
    "评论数据以单词索引的形式加载，正面和负面评论分别标注为1和0。\n",
    "提取评论的最大和最小长度，以了解数据的分布情况。\n",
    "数据预处理：\n",
    "\n",
    "使用单词到索引的映射将索引序列转换回评论文本，方便查看评论内容。\n",
    "将所有评论填充或截断为固定长度500，以便输入到神经网络中进行训练。\n",
    "构建情感分析模型：\n",
    "\n",
    "创建一个顺序模型，包含以下层：\n",
    "Embedding层：将单词索引映射为嵌入向量，大小为32，用于捕获单词之间的语义关系。\n",
    "LSTM层：具有100个单元，用于提取评论中的时间序列特征。\n",
    "Dense层：使用sigmoid激活函数，将LSTM的输出映射为一个概率值，用于二分类。\n",
    "最后打印模型的结构信息。\n",
    "'''\n",
    "\n",
    "from keras.datasets import imdb\n",
    "#Set the vocabulary size and load in training and test data.\n",
    "vocabulary_size = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n",
    "print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))\n",
    "\n",
    "word2id = imdb.get_word_index()\n",
    "id2word = {i: word for word, i in word2id.items()}\n",
    "print('---review with words---')\n",
    "print([id2word.get(i, ' ') for i in X_train[6]])\n",
    "print('---label---')\n",
    "print(y_train[6])\n",
    "\n",
    "print('Maximum review length: {}'.format(\n",
    "len(max((X_train + X_test), key=len))))\n",
    "#Maximum review length: 2697\n",
    "print('Minimum review length: {}'.format(\n",
    "len(min((X_test + X_test), key=len))))\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "embedding_size=32\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())\n"
   ],
   "id": "7ba74fe03a5faffd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "'''\n",
    "库的导入：导入了numpy、Keras等库，用于数据处理、模型定义和训练。\n",
    "\n",
    "函数定义：generate_seq：\n",
    "\n",
    "这是一个生成文本序列的函数，它基于训练好的模型和种子文本生成新的单词。\n",
    "in_text是开始的种子文本，通过循环将预测的单词逐步添加到in_text，生成一段指定长度的文本。\n",
    "准备文本数据：\n",
    "\n",
    "data是输入的文本，描述了“Jack and Jill”的故事。\n",
    "通过Tokenizer将文本转换为整数序列，即将每个单词映射到一个唯一的整数值。\n",
    "计算词汇表大小，以便定义嵌入层的输入维度。\n",
    "生成训练数据：\n",
    "\n",
    "创建序列用于训练，使用前两个单词预测下一个单词。\n",
    "例如，对于句子“Jack and Jill went”，序列生成会是“Jack and Jill -> Jill went”这样的三元组，最后一个单词是目标。\n",
    "填充序列：\n",
    "\n",
    "由于文本的不同部分可能长度不同，通过pad_sequences对序列进行填充，使它们的长度一致，便于模型处理。\n",
    "输入和输出的拆分：\n",
    "\n",
    "输入（X）是句子中前两个单词的整数表示，输出（y）是预测的目标单词。\n",
    "通过to_categorical将输出转换为独热编码，便于分类训练。\n",
    "定义模型：\n",
    "\n",
    "使用Keras定义了一个顺序模型（Sequential）。\n",
    "第一个层是嵌入层（Embedding），用于将整数序列转换为稠密的向量表示。\n",
    "接着是一个LSTM层，用于处理序列数据。\n",
    "最后是一个全连接的输出层，用于预测下一个单词的概率分布。\n",
    "编译和训练模型：\n",
    "\n",
    "使用categorical_crossentropy损失函数和adam优化器来编译模型。\n",
    "用输入X和输出y训练模型500次。\n",
    "生成新文本：\n",
    "\n",
    "使用generate_seq函数基于不同的种子文本生成新的单词。\n",
    "'''\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "\n",
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, max_length, seed_text, n_words):\n",
    "\tin_text = seed_text\n",
    "\t# generate a fixed number of words\n",
    "\tfor _ in range(n_words):\n",
    "\t\t# encode the text as integer\n",
    "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "\t\t# pre-pad sequences to a fixed length\n",
    "\t\tencoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "\t\t# predict probabilities for each word\n",
    "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
    "\t\t# map predicted word index to word\n",
    "\t\tout_word = ''\n",
    "\t\tfor word, index in tokenizer.word_index.items():\n",
    "\t\t\tif index == yhat:\n",
    "\t\t\t\tout_word = word\n",
    "\t\t\t\tbreak\n",
    "\t\t# append to input\n",
    "\t\tin_text += ' ' + out_word\n",
    "\treturn in_text\n",
    "\n",
    "# source text\n",
    "data = \"\"\" Jack and Jill went up the hill\\n\n",
    "\t\tTo fetch a pail of water\\n\n",
    "\t\tJack fell down and broke his crown\\n\n",
    "\t\tAnd Jill came tumbling after\\n \"\"\"\n",
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "encoded = tokenizer.texts_to_sequences([data])[0]\n",
    "# retrieve vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)\n",
    "# encode 2 words -> 1 word\n",
    "sequences = list()\n",
    "for i in range(2, len(encoded)):\n",
    "\tsequence = encoded[i-2:i+1]\n",
    "\tsequences.append(sequence)\n",
    "print('Total Sequences: %d' % len(sequences))\n",
    "# pad sequences\n",
    "max_length = max([len(seq) for seq in sequences])\n",
    "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
    "print('Max Sequence Length: %d' % max_length)\n",
    "# split into input and output elements\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1],sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=max_length-1))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())\n",
    "# compile network\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "model.fit(X, y, epochs=500, verbose=2)\n",
    "# evaluate model\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'Jack and', 5))\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'And Jill', 3))\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'fell down', 5))\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'pail of', 5))"
   ],
   "id": "d034b26cdcec1b37"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "'''\n",
    "这段代码实现了一个简单的卷积神经网络（CNN）来对MNIST数据集进行分类。MNIST数据集是一个手写数字的数据集，包含从0到9的数字。以下是对代码的逐步解释：\n",
    "\n",
    "1. 导入必要的库\n",
    "使用了Keras库来构建和训练卷积神经网络。\n",
    "导入了必要的模块和函数，例如卷积层、池化层、全连接层等。\n",
    "2. 定义参数\n",
    "num_classes：类别数量（10个，分别对应数字0-9）。\n",
    "num_epochs：训练过程中遍历数据的次数，这里设为1。\n",
    "img_rows, img_cols：输入图片的大小（28x28像素）。\n",
    "3. 加载MNIST数据集\n",
    "mnist.load_data() 返回训练和测试数据集。\n",
    "x_train、y_train为训练数据及标签，x_test、y_test为测试数据及标签。\n",
    "4. 数据预处理\n",
    "根据后端（Theano或TensorFlow）的偏好，调整数据的形状。TensorFlow使用(rows, cols, channels)格式，Theano使用(channels, rows, cols)格式。\n",
    "将像素值归一化到0-1之间（将像素值除以255），以便更快地训练模型。\n",
    "将标签转换为独热编码（one-hot encoding）格式，例如数字“3”转换为[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]。\n",
    "5. 打印样本数量\n",
    "打印训练和测试样本的数量。\n",
    "6. 构建卷积神经网络模型\n",
    "构建了一个顺序模型（Sequential）。\n",
    "卷积层（Conv2D）：使用32个3x3大小的卷积核，激活函数为ReLU，输入形状为(28, 28, 1)。\n",
    "池化层（MaxPooling2D）：使用2x2大小的最大池化层来减少特征图的大小，从而加快计算并避免过拟合。\n",
    "代码中有注释提到如果添加更多的池化层可能会进一步加快计算，但会导致准确度下降。\n",
    "Flatten层：将特征图转换为一维向量，以便传递给全连接层。\n",
    "全连接层（Dense）：128个神经元，激活函数为ReLU。\n",
    "输出层（Dense）：输出大小为num_classes（即10），激活函数为softmax，用于多分类问题。\n",
    "7. 编译模型\n",
    "使用损失函数categorical_crossentropy，适用于多分类问题。\n",
    "使用优化器sgd（随机梯度下降）。\n",
    "指标为准确率。\n",
    "8. 训练模型\n",
    "使用model.fit()对训练数据进行训练，epochs=num_epochs表示训练数据遍历的次数。\n",
    "使用validation_data在训练过程中评估模型的性能。\n",
    "9. 评估模型\n",
    "使用model.evaluate()在测试集上评估模型，返回测试损失和测试准确率。\n",
    "打印出测试集上的损失和准确率。\n",
    "10. 保存模型\n",
    "保存模型结构：使用YAML格式将模型保存到文件model.yaml中。\n",
    "保存模型权重：将模型的权重保存到文件model_weights.h5中。\n",
    "'''\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_yaml\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "\n",
    "\n",
    "# A \"class\" for each digit from 0-9\n",
    "num_classes = 10\n",
    "# How many times to run through the data while training\n",
    "num_epochs = 1\n",
    "# Input (image) dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# mnist.load_data() returns 2 tuples split into training/testing\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Need to reshape data based on backend preferred image format (TF vs Theano)\n",
    "if K.image_data_format() == 'channels_first':\n",
    "\tx_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols).astype('float32')\n",
    "\tx_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols).astype('float32')\n",
    "\tinput_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "\tx_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1).astype('float32')\n",
    "\tx_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1).astype('float32')\n",
    "\tinput_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# Normalize pixel values between 0 and 1 per color channel for easier training\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Convert class label values to one-hot vectors [0, 0, ..., 1, 0, ..., 0]\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Print out sample sizes\n",
    "print(\"Training samples:\", x_train.shape[0])\n",
    "print(\"Test samples:\", x_test.shape[0])\n",
    "\n",
    "# Build model\n",
    "model = Sequential()\n",
    "# Convolutional Layer (input shape specified because its the first layer\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "# Pooling Layer (speeds up computation somewhat by decreasing data size and\n",
    "# \t\t\t\t allows for more local features to be learned)\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "# speeds up from 1min to 40 seconds but worse accuracy\n",
    "#model.add(MaxPooling2D((2, 2)))\n",
    "# doesn't speed up anymore and worse accuracy\n",
    "#model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flattens data into one dimension for fully connected layer to follow\n",
    "model.add(Flatten())\n",
    "# Fully Connected Layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# Output layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Choosing loss function and optimizer for training\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "\t\t\t\toptimizer='sgd',\n",
    "\t\t\t\tmetrics=['accuracy'])\n",
    "\n",
    "# Fit to training data (like sklearn classifiers)\n",
    "model.fit(x_train, y_train, \n",
    "\t\t  epochs=num_epochs, \n",
    "\t\t  validation_data=(x_test, y_test))\n",
    "\n",
    "# Save metrics of network like accuracy for observation\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Print out results\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy: {:.2f}%\".format(score[1]*100))\n",
    "\n",
    "# Save model\n",
    "model_yaml = model.to_yaml()\n",
    "with open('model.yaml', 'w') as yaml_file:\n",
    "\tyaml_file.write(model_yaml)\n",
    "\n",
    "# Save weights\n",
    "model.save_weights('model_weights.h5')\n",
    "print('Saved model and weights to disk.')"
   ],
   "id": "4cb3eabd76aa9ad5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
